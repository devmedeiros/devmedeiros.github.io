<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>machine learning on devmedeiros</title>
    <link>https://devmedeiros.com/tags/machine-learning/</link>
    <description>Recent content in machine learning on devmedeiros</description>
    <image>
      <title>devmedeiros</title>
      <url>https://devmedeiros.com/cover.png</url>
      <link>https://devmedeiros.com/cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 03 Oct 2023 20:51:00 -0300</lastBuildDate><atom:link href="https://devmedeiros.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Keeping Up with the Latest in Machine Learning Models</title>
      <link>https://devmedeiros.com/post/keeping-up-machine-learning/</link>
      <pubDate>Tue, 03 Oct 2023 20:51:00 -0300</pubDate>
      
      <guid>https://devmedeiros.com/post/keeping-up-machine-learning/</guid>
      <description>How to keep up with the latest disicoveries in Machine Learning Models and academic research.</description>
      <content:encoded><![CDATA[<p>Every day new research regarding Machine Learning is being published, and it may seem impossible to keep up with all the new models and applications that people are using. So I want to talk about my two favorite ways to keep up with new research and know about what people are working on.</p>
<h2 id="1---two-minute-papers">1 - Two Minute Papers</h2>
<p>This YouTube <a href="https://www.youtube.com/@TwoMinutePapers">channel</a> is my favorite one to keep up with new research regarding Machine Learning. They are always releasing new videos talking about papers showing what researchers have just published, focusing mainly on the results, but always linking the original paper so you can read more about it.</p>
<p>Two Minute Papers have been covering the OpenAI discoveries for quite some time now, I remember seeing videos about what ChatGPT could do, before it was open to the public, and it compared it with previous versions. So you can see the progress being made, even if you miss the older videos, they always make a comparison with previous versions when available.</p>
<p>The videos are kept in an approachable language, so even beginners can understand the main points. Additionally, the channel also makes the videos entertaining, so it&rsquo;s easy to keep watching and stack on more knowledge.</p>
<h2 id="2---papers-with-code">2 - Papers with Code</h2>
<p><a href="paperswithcode.com">Papers with Code</a> is more than a website that just indexes papers. It makes it easier to find papers with code about Machine Learning, linking the papers, the source code, and even datasets.</p>
<p>If you want to learn about the state-of-the-art of a specific topic in Machine Learning you can browse between tasks, for example, if you are looking for more information about Natural Language Processing, you can choose a specific task, like Named Entity Recognition, then you&rsquo;ll be able to see the current benchmarks, according to database, the best model, the model paper and source code. It also links the databases used to research the specific task you choose and it links libraries that you can use to apply the models.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>What is Anomaly Detection?</title>
      <link>https://devmedeiros.com/post/anomaly-detection/</link>
      <pubDate>Sun, 09 Jul 2023 16:32:00 -0300</pubDate>
      
      <guid>https://devmedeiros.com/post/anomaly-detection/</guid>
      <description>How can your credit card issuer know if a purchase is made by you or a cloned version of your credit card?</description>
      <content:encoded><![CDATA[<p>Have you ever had a purchase blocked by your credit card issuer without you taking any action? If this happened to you, your credit card issuer probably had detected that your purchase didn&rsquo;t match your <em>normal spending habit</em>, maybe you were at a different location or spend a lot of money suddenly. Anyway, the credit card company was using <strong>anomaly detection</strong> techniques to prevent fraudulent activities.</p>
<h2 id="what-is-anomaly-detection">What is Anomaly Detection?</h2>
<blockquote>
<p><em>Anomaly detection</em> refers to the problem of finding patterns in data that do not conform to expected behavior. <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>In statistics there is a famous distribution that is called &ldquo;The Normal Distribution&rdquo;, this name is not in vain. A lot of random things are normally distributed, for instance, if you select 100 random people and measure their height, and made a distribution plot, you&rsquo;d end up with something looking like a symmetrical bell curve.</p>
<p>Even though abnormal results are possible, it is expected that most people or things will fall within a normal distribution. When something is divergent from this normality it is said to be an outlier or an anomaly.</p>
<p>When dealing with something like credit card fraud you can create an expectation of a person expanding habits, so if your daily routine consists of waking up and driving to your workplace and buying a coffee, then lunch in New York. Your credit card company would find it weird if you suddenly made a physical purchase in Rio de Janeiro.</p>
<p>In simple terms, that is what anomaly detection is trying to do, understand how something works so it can identify if it starts acting weird.</p>
<h2 id="anomaly-detection-x-class-imbalance-in-datasets">Anomaly Detection x Class Imbalance in Datasets</h2>
<p>If you are aware of what class imbalance is, you may be wondering <em>&ldquo;can&rsquo;t I use anomaly detection to solve this class imbalance problem?&rdquo;</em> - sometimes you can, but it&rsquo;s not appropriate.</p>
<p>Class imbalance occurs when one class has significantly more samples than the other class(es). This can lead to biased models that favor the majority class and perform poorly on minority classes. While anomaly detection focuses on identifying rare or abnormal data points that deviate significantly from the normal patterns in the dataset.</p>
<p>Even though it has some overlap on what is trying to do, unless you have a class imbalance problem that the minority class can be considered an abnormal behavior, you won&rsquo;t be able to use anomaly detection.</p>
<hr>
<p>I talked about class imbalance before on a churn rate problem in a fictitious telecommunication company, if you are interested you can check it <a href="/post/2022-05-30-churn-rate-challenge/">here</a>.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Chandola, V., Banerjee, A., and Kumar, V. 2009. Anomaly detection: A survey. ACM Comput. Surv. 41, 3, Article 15 (July 2009), 58 pages. DOI = <a href="http://doi.acm.org/10.1145/1541880.1541882">10.1145/1541880.1541882</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Is Machine Learning Necessary for Your Business?</title>
      <link>https://devmedeiros.com/post/unlocking-machine-learning/</link>
      <pubDate>Sat, 20 May 2023 19:46:00 -0300</pubDate>
      
      <guid>https://devmedeiros.com/post/unlocking-machine-learning/</guid>
      <description>Find out if the use of machine learning is essential in all business cases. Evaluate benefits and limitations.</description>
      <content:encoded><![CDATA[<p>In the increasingly data-driven business world, machine learning has gained prominence as a powerful tool to drive business success. However, a crucial question arises: is machine learning really necessary in all cases? In this post, we&rsquo;ll delve into that discussion, exploring the applications, benefits, and limitations of machine learning. In addition, we will provide useful criteria to help you decide whether this approach is essential for your business.</p>
<h2 id="what-is-machine-learning">What is Machine Learning?</h2>
<p>Machine Learning (ML) is a term used to describe algorithms that can be modeled to predict or explain something. You can make <em>machine learning models</em> that can predict monthly sales, customer churn, recommendation systems, etc.</p>
<p>To make these models you&rsquo;ll need a lot of data, but not only that. You&rsquo;ll need good data, unbiased and clean.</p>
<p>These models can be written in many different programming languages, the most popular ones are <strong>Python</strong> and <strong>R</strong>, but you could also use <strong>Julia</strong>, <strong>Scala</strong>, <strong>GO</strong>, and many others.</p>
<h2 id="machine-learning-cases">Machine Learning Cases</h2>
<h3 id="recommendation-systems">Recommendation Systems</h3>
<p>If you ever wonder how your favorite streaming service always has a new song or show recommended to you, this is thanks to recommendation systems. They have many different algorithms to guess what a user would like.</p>
<p>One of these algorithms creates clusters of similar users and uses things the other users enjoy to recommend to you. A simpler approach would just recommend the most popular items.</p>
<h3 id="customer-churn">Customer Churn</h3>
<p>This kind of model is really popular amongst companies like internet providers and banks. These models look at customer behavior when interacting with the company to try to identify what causes a customer to <em>give up</em> working with them.</p>
<p>Is useful to find problems in a company regarding customer experience and the quality of the services provided.</p>
<h2 id="the-benefits-of-machine-learning">The benefits of Machine Learning</h2>
<p>With Machine Learning companies can make informed decisions about their business. For example, a restaurant can predict how many meals are going to be ordered weekly and then buy enough ingredients to avoid wasting food; or a company can calculate how likely a certain customer is to churn and then offer discounts or better deals to try to keep the customer.</p>
<p>These processes can be automated and - <em>if the model is well built</em> - it&rsquo;ll only get better with time, increasing the accuracy and overall efficiency.</p>
<h2 id="limitations">Limitations</h2>
<p>Even though Machine Learning is incredible and sometimes looks like it came out of a sci-fi movie, it&rsquo;s not a solution that fits all. Some business problems don&rsquo;t have enough quality data to build a model, and even when you do have it, the computing power and expertise needed make it an expensive tool.</p>
<p>Sometimes you can achieve a close result to an ML model by just taking a moving average, it&rsquo;s not perfect, but when you take into consideration the investment and the return of both approaches, it may make more sense to choose the cheaper option first, before moving into more complex models.</p>
<h2 id="how-to-decide-if-machine-learning-is-needed">How to decide if Machine Learning is Needed</h2>
<p>Before deciding if an ML model is necessary check if you already accomplished the following things:</p>
<ul>
<li>you have a quality data pipeline</li>
<li>your company is data-driven</li>
<li>you have the budget to invest in a data science team or to hire a company to do it</li>
<li>your problem can be solved with ML</li>
<li>have you already tested/tried simpler options available</li>
</ul>
<p>These aren&rsquo;t rules written in stone, just something that I think is important to keep in mind before choosing to invest in Machine Learning. You don&rsquo;t want to spend time working on something just to give up because then you realized that ML doesn&rsquo;t fit your business needs or it doesn&rsquo;t deliver extraordinary results.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Credit Score Classification App</title>
      <link>https://devmedeiros.com/post/credit-score-classification-app/</link>
      <pubDate>Mon, 08 Aug 2022 17:17:00 -0300</pubDate>
      
      <guid>https://devmedeiros.com/post/credit-score-classification-app/</guid>
      <description>Using Streamlit to make a web app that classifies your credit score using Python</description>
      <content:encoded><![CDATA[<h2 id="project-overview">Project Overview</h2>
<p>This project showcase a data science life cycle, where I clean and prepare the dataset, use feature engineering, machine learning, deploy, and data visualization.</p>
<p><img loading="lazy" src="https://ik.imagekit.io/devmedeiros/data-science-cycle_QZwyHaXsP.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1659975338736#center" alt="data science cycle of this project in a diagram"  />
</p>
<p>The dataset comes from <a href="https://www.kaggle.com/datasets/parisrohan/credit-score-classification?select=train.csv">kaggle</a>, it has a lot of information about a person&rsquo;s credit and bank details, but it also has a lot of typos, missing data, and censored data. This dataset needed cleaning and also needed some feature engineering, I needed to mutate some features, so they could be read by the model. Thus when presented with categorical data I needed to identify if it was ordinal or nominal, if it was an ordinal variable then it would be mapped to sequential numbers otherwise I&rsquo;d make a dummy. For <em>yes</em> and <em>no</em> variables I choose to make just one dummy, but for types of loans I made one dummy for each loan type and if someone didn&rsquo;t have a loan they simply get 0 on all loan type features. I talk about the process of cleaning and feature engineering on this dataset <a href="/post/data-cleaning-credit-score/">here</a>.</p>
<p>Then I needed a machine learning model that I could predict a person&rsquo;s credit score based on some features. To decide which features I was going to use I based my decision on what is commonly used among real companies, and I also choose variables that I thought made sense. I ended up with the following features:</p>
<ul>
<li>Age</li>
<li>Annual income</li>
<li>Number of bank accounts</li>
<li>Number of credit cards</li>
<li>Number of delayed payments</li>
<li>Credit card utilization ratio</li>
<li>Total EMI paid monthly</li>
<li>Credit history age in months</li>
<li>Loans</li>
<li>Missed any payment in the last 12 months</li>
<li>Paid minimum amount on at least one credit card</li>
</ul>
<p>With the features ready, I moved on to making the model, I decided to use a simple Random Forest, for now, I do intend to work on making this model better, but in this first instance, I wanted to focus on making the streamlit app.</p>
<p>After I finished the model I serialized it and the scaler using the <code>pickle</code> package. To deploy the model and build a visualization I used <a href="https://streamlit.io/">streamlit</a>.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/33239902/183321842-be97fb04-f00b-4b62-8e6e-2b53d25335a0.gif" alt="a gif showing how the streamlit credit score app works"  />
</p>
<p>In this app, you can fill out a form or just select one of the three default profiles given to see how the model evaluates each person&rsquo;s credit score. It also presents how certain the model was by displaying a pie graph with the probability (in percentage) of each credit score group the answers fit. It also shows how much each feature counts towards your credit score, according to this model. You can see the app live <a href="https://devmedeiros-credit-score-classification-appstreamlit-app-fcakrl.streamlitapp.com/">here</a>.</p>
<hr>
<p>All of the code is available at my GitHub <a href="https://github.com/devmedeiros/credit-score-classification-app">repository</a>. Besides the code, there you&rsquo;ll find the documentation, the original and treated data (all the stages of treatment), all the requirements for building this project, and how to run it locally.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Data Science Challenge - Churn Rate</title>
      <link>https://devmedeiros.com/post/2022-05-30-churn-rate-challenge/</link>
      <pubDate>Mon, 30 May 2022 16:49:00 -0300</pubDate>
      
      <guid>https://devmedeiros.com/post/2022-05-30-churn-rate-challenge/</guid>
      <description>Alura hosted a four-week Data Science Challenge using an imbalanced dataset of Churn Rate of a company Alura Voz</description>
      <content:encoded><![CDATA[<p>I was challenged to take the role of a new data scientist hired at Alura Voz. This made-up company is a telecommunication company and it needs to reduce the Churn Rate.</p>
<p>The challenge is divided into four weeks. For the first week, the goal was to clean the dataset provided by an API. Next, we need to identify clients who are more likely to leave the company, using data exploration and analysis. Then, in the third week, we made machine learning models to predict the churn rate for Alura Voz. The last week is to show off what we made during the challenge and build our portfolio. In case you are interested in seeing the code for the challenge just head over to my GitHub <a href="https://github.com/devmedeiros/Challenge-Data-Science">repository</a>.</p>
<h2 id="first-week">First Week</h2>
<h3 id="reading-the-dataset">Reading the dataset</h3>
<p>The dataset is available in a JSON file, at first glance it looked like a normal data frame.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/1%20-%20Data%20Cleaning/table_head.png#center" alt="table head with the first five rows"  />
</p>
<p>But, as we can see, <code>customer</code>, <code>phone</code>, <code>internet</code>, and <code>account</code> are their own separate table. So I had to normalize them separately and then I just concatenated all these tables into one.</p>
<h3 id="missing-data">Missing data</h3>
<p>The first time I looked for missing data in this dataset I notice that apparently, that wasn&rsquo;t anything missing, but later on, I noticed that there was empty space and just space not being counted as <code>NaN</code>. So I corrected this, and now the dataset had 224 missing values for <code>Churn</code> and 11 missing for <code>Charges.Total</code>.</p>
<p>I decided to drop the missing <code>Churn</code> because this is going to be the object of our study and there isn&rsquo;t a point in studying something that doesn&rsquo;t exist. For the missing <code>Charges.Total</code>, I think it represents a customer that hasn&rsquo;t paid anything yet, because all of them had a tenure of 0, meaning that they had just become a client, so I just replaced the missing value for 0.</p>
<h3 id="feature-encoding">Feature Encoding</h3>
<p>The feature <code>SeniorCitizen</code> was the only one that came with <code>0</code> and <code>1</code> instead of <code>Yes</code> and <code>No</code>. For now, I&rsquo;m changing it to yes and no, because it&rsquo;ll make the analysis simpler to read.</p>
<p><code>Charges.Monthly</code> and <code>Charges.Total</code> were renamed to lose the dot because the dot gets in the way when calling the feature in python.</p>
<h2 id="second-week">Second Week</h2>
<h3 id="data-analysis">Data Analysis</h3>
<p>In the first plot, we can see how much unbalanced our data set is. There&rsquo;re over 5000 clients that didn&rsquo;t leave the company and a little less than 2000 that left.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/2%20-%20Data%20Analysis/churn.jpg#center" alt="bar plot with two bars, the first one is for &amp;rsquo;no&amp;rsquo; and the second is for &amp;lsquo;yes&amp;rsquo;, the first bar is over 5000 count and the second one is around 2000"  />
</p>
<p>I experimented with oversampling the dataset to handle this imbalance, but it made the machine learning models worse. And undersampling isn&rsquo;t an option with this dataset size, so I just decided to leave it the way it is, and when it&rsquo;s time to split the training and test set I&rsquo;ll stratify the dataset by the <code>Churn</code> feature.</p>
<p>I also generated 16 plots for all the discrete data, to see all the plots check this <a href="https://github.com/devmedeiros/Challenge-Data-Science/blob/main/2%20-%20Data%20Analysis/data_analysis.ipynb">notebook</a>. I wanted to see if there was any behavior that made some clients more likely to leave the company. Is clear that all, except for <code>gender</code>, seems to play a role in determining if a client will leave the company or not. More specifically payment methods, contracts, online backup, tech support, and internet service.</p>
<p>In the <code>tenure</code> plot, I decided to make a distribution plot for the tenure, one plot for clients that didn&rsquo;t churn and another for the clients that did churn. We can see that clients that left the company tend to do so at the beginning of their time in the company.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/2%20-%20Data%20Analysis/tenure.jpg#center" alt="there are two plots side-by-side, in the first one the title is &amp;lsquo;Churn = No&amp;rsquo; the data is along the tenure axis and is in a U shape. the second plot has the title &amp;lsquo;Churn = Yes&amp;rsquo; and starts high and drops fast along the tenure line"  />
</p>
<p>The average monthly charge for clients that didn&rsquo;t churn is 61.27 monetary units, while clients that churn were paying 74.44. This is probably because of the type of contract they prefer, but either way is known that higher prices drive the customers away.</p>
<h3 id="the-churn-profile">The Churn Profile</h3>
<p><img loading="lazy" src="https://64.media.tumblr.com/tumblr_lojvnhHFH91qlh1s6o1_400.gifv#center" alt="person jumping through the window"  />
</p>
<p>Considering everything that I could see through plots and measures. I came up with a profile for clients that are more likely to churn.</p>
<ul>
<li>
<p>New clients are more likely to churn than older clients.</p>
</li>
<li>
<p>Customers that use fewer services and products tend to leave the company. Also, when they aren&rsquo;t tied down to a longer contract they seem to be more likely to quit.</p>
</li>
<li>
<p>Regarding the payment method, clients that churn have a <strong>strong</strong> preference for electronic checks and usually are spending 13.17 monetary units more than the average client that didn&rsquo;t leave.</p>
</li>
</ul>
<h2 id="third-week">Third Week</h2>
<h3 id="preparing-the-dataset">Preparing the dataset</h3>
<p>We start by making dummies variables dropping the first, so we would have n-1 dummies for n categories. Then we move on to look at features correlation.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/3%20-%20Model%20Selection/corr_matrix.jpg#center" alt="correlation matrix with all the features"  />
</p>
<p>We can see that the <code>InternetService_No</code> feature has a lot of strong correlations with many other features, this is because these other features depend on the client having internet service. So I&rsquo;ll drop all features that are dependent on this one. The same thing happens with <code>PhoneService_Yes</code>.</p>
<p><code>tenure</code> and <code>ChargesTotal</code> also have a strong correlation, so I tried running the models without one of them and both, and it had a worse performance and took a long time to converge, so I decided to keep them as they are relevant as well.</p>
<p>After dropping the features I finish preparing the dataset by normalizing the numeric data, <code>ChargesTotal</code> and <code>tenure</code>.</p>
<h3 id="test-and-training-dataset">Test and training dataset</h3>
<p>I split the dataset into training and testing sets, 20% for testing and the rest for training. I stratified the data by the <code>Churn</code> feature and I shuffle the dataset before splitting. The same split is used by all the models. After splitting the dataset I decided to oversample the <strong>train</strong> data using SMOTE<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> because the dataset is imbalanced. The reason that I only used this technique on the training set is that I don&rsquo;t want to have a biased result, oversampling all the datasets would mean that I&rsquo;d be testing my models on the same data that I trained, and that&rsquo;s not the goal here.</p>
<h3 id="model-evaluation">Model Evaluation</h3>
<p>I&rsquo;ll use a dummy classifier to have a baseline model for the accuracy score, and I&rsquo;ll also use the metrics: <code>precision</code>, <code>recall</code> and <code>f1 score</code><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Although the dummy model won&rsquo;t have values for this metrics, I&rsquo;ll keep it for comparison on how much the models improved.</p>
<h3 id="baseline">Baseline</h3>
<p>I made the baseline model using a dummy classifier that guessed that every client behaved the same. It is always guessed that no client will leave the company. By using this approach we got a baseline accuracy score of <code>0.73456</code>.</p>
<p>All models moving forward will have the same random state.</p>
<h3 id="model-1---random-forest">Model 1 - Random Forest</h3>
<p>I start by using a grid search with cross-validation to find the best parameters within a given pool of options using the <code>recall</code> as the strategy to evaluate the performance. The best model was:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>RandomForestClassifier(criterion<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;entropy&#39;</span>, max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, max_leaf_nodes<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">22</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>After fitting this model, the evaluating metrics were:</p>
<ul>
<li>Accuracy Score: 0.72534</li>
<li>Precision Score: 0.48922</li>
<li>Recall Score: 0.78877</li>
<li>F1 Score: 0.60389</li>
</ul>
<h3 id="model-2---linear-svc">Model 2 - Linear SVC</h3>
<p>For this model, I just used the default parameters and set the ceiling for the maximum of iterations to <code>900000</code>.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>LinearSVC(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">900000</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">22</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>After fitting this model, the evaluating metrics were:</p>
<ul>
<li>Accuracy Score: 0.71966</li>
<li>Precision Score: 0.48217</li>
<li>Recall Score: 0.75936</li>
<li>F1 Score: 0.58982</li>
</ul>
<h3 id="model-3---multi-layer-perceptron">Model 3 - Multi-layer Perceptron</h3>
<p>Here I fixed the solver to LBFGS, because according to the documentation it has a better performance in smaller datasets<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, and used grid search with cross-validation to find a hidden layer size that would be the best. The best model was:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>MLPClassifier(hidden_layer_sizes<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,), max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">9999</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">22</span>, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;lbfgs&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>After fitting this model, the evaluating metrics were:</p>
<ul>
<li>Accuracy Score: 0.72818</li>
<li>Precision Score: 0.49133</li>
<li>Recall Score: 0.68182</li>
<li>F1 Score: 0.57111</li>
</ul>
<h3 id="conclusion">Conclusion</h3>
<p>After running the three models, all of them used the same random_state. I got the following accuracy scores and improvements (compared to the baseline model):</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/3%20-%20Model%20Selection/results_table.png#center" alt="results table"  />
</p>
<p>In the end, the Random Forest had the best metrics overall. This model can <em>recall</em> a great portion of clients that churn correctly, still is not perfect but is certainly a starting point. The <em>accuracy</em> score is not as high as I&rsquo;d like, but in this particular problem, the goal is to keep clients from leaving the company and is better to use resources to keep a client that will not leave than to do nothing.</p>
<p>In the end, I liked this challenge, because I don&rsquo;t usually practice machine learning, but thanks to the challenge I got the chance to make a small project in this area that is so relevant and important. This was my first time working with neural networks and tunning hyper-parameters, and I&rsquo;m sure the next time I&rsquo;ll get even better results.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html">imbalanced-learn documentation</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9">Accuracy, Precision, Recall or F1? - Koo Ping Shung</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">scikit-learn documentation</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
