[{"content":"O que é UX/UI? UX é a sigla em inglês para Experiência de Usuário, é um conceito recente que fala sobre tomar decisões de design pensando na experiência do usuário final. O designer de UX precisa se preocupar se seu produto é fácil de usar e intuitivo, fazendo mudanças nele sempre que necessário para se adequar as necessidades do usuário.\nUI, do inglês, significa Interface do Usuário. É tudo aquilo que está envolvido na interação do usuário e o produto. O designer de UI é responsável por desenvolver interfaces, não limitado apenas aos aspectos visuais, também é importante garantir que sejam funcionais, usáveis, e que em geral, contribuem para uma boa experiência do usuário.\nComo Melhorar a Experiência dos Painéis de BI? Muitos pessoas veem os painéis de BI como páginas de web e isso traz algumas expectativas de uso. Por exemplo, a maioria dos sites que possuem algum sistema de navegação usam um menu superior com botões, um menu lateral (mais comum no Brasil sendo na esquerda, mas em alguns países é na direita) ou um menu sanduíche (aquele que clicamos no botão e aparece as opções).\n\r\rJaqueline Medeiros - Todos os direitos reservados\n\r\rCom isso uma grande parcela das pessoas que utilizam os painéis esperam encontrar botões de navegação e segmentação (filtro) de dados nestes locais, além de outras informações como logo e título.\nSegmentação de Dados Também comummente chamado de filtro de dados é uma peça fundamental de diversos dashboards, seu posicionamento precisa ser definido com cuidado, pois se estiver num lugar que o usuário não espera pode impedir que seu painel seja usado eficientemente, além disso manter um padrão visual para todos os seus filtros ajudam as pessoas a reconhecerem mais facilmente o que é ou não é um filtro.\n\r\rVocê pode e deve usar e experimentar com diversos temas nos seus trabalhos. O que importa, na hora de facilitar para os usuários, é a consistência, escolha um modelo de filtro com as cores desejadas e todas as especificações gráficas que são do seu interesse e utilize ela em todos os filtros, pois isso irá ajudar as pessoas a baterem o olho e reconhecer que aquilo é um filtro.\nÉ muito comum as pessoas quando estão lendo algo pelo computador posicionarem o ponteiro do mouse onde elas estão lendo. No caso do Power BI, isso torna mais fácil para o usuário encontrar o botão de limpar a segmentação de dados, pois ao passar o mouse no nome do filtro aparece uma borrachinha no lado esquerdo onde fica o nome do filtro. Tá mais se você usa o Power BI provavelmente já sabia disso, mas podemos melhorar isso usando algo que o usuário já conhece, que é a borrachinha, e criar um botão usando a borrachinha como ícone e fazer com que esse botão limpe todos os filtros ao mesmo tempo. Caso queira saber como fazer esse botão aqui no fórum do Power BI explica como.\nEssa é uma característica que pode ter sua importância despercebida num primeiro momento, mas algo que ocorre muito é os usuários do painel não perceberem quais filtros eles usaram ou usarem tantos que só querem poder limpar a seleção de forma mais rápida e eficiente, então esse botão torna o processo muito mais user friendly.\nNavegação de Página A navegação de páginas nativa do Power BI não é intuitiva para a maioria das pessoas e em muitas vezes você pode querer direcionar a navegação num fluxo específico que facilita o entendimento e contribui para o storytelling planejado. Neste caso temos a opção de ocultar todas as abas do relatório, exceto uma que é a página de abertura/inicial. Mas qual a melhor forma de direcionar o usuário para as demais páginas? Bem, isso depende do que você está fazendo. Suponha que seu relatório seja bem simples, você tem uma aba de visão geral e outra aba com um detalhamento, um simples botão resolveria o seu problema, mas caso seu relatório seja muito extenso pode ser inviável colocar um botão para cada aba em todas as páginas.\n\r\rJaqueline Medeiros - Todos os direitos reservados\n\r\rNeste caso pode ser interessante considerar ter uma página inicial que leva a todas as páginas do relatório e colocar um botão de home ou voltar nas outras páginas.\nComo Melhorar a Interface dos Dashboards? Programas de Prototipagem Usar um programa específico para fazer o protótipo do seu painel permite uma liberdade artística maior comparado ao que os aplicativos de Business Intelligence normalmente fornecem. O Figma é ótimo para isso, você pode criar backgrounds e protótipos avançados com ótima qualidade para usar em seus painéis de BI.\nVeja um exemplo de um painel que eu fiz a alguns meses atrás:\n\r\rPainel com os dados\r\r\rO plano de fundo desse painel foi feito completamente no Figma, até mesmo alguns dos títulos dos visuais do BI.\n\r\rBackground feito no Figma\r\r\rVocê pode encontrar mais painéis de Power BI que eu fiz para o Alura Challenge: Alura Films, Alura Skimo, and Alura Food.\nFiguras e Ícones \rVetor criado por pch.vector - br.freepik.com\n\r\rFiguras e ícones quando usados corretamente ajudam a destacar o painel, o torna mais chamativo e bonito. Há diversas formas de se conseguir imagens, caso você ou sua equipe não consigam criar vocês mesmo existe a opção de usar plataformas online que disponibilizam imagens vetorizadas. Nessas plataformas existem as opções gratuitas, em que exigem algum tipo de atribuição, e opções premium (pagas), em que muitas vezes não precisa atribuir o autor e possuem uma qualidade maior.\n\rÍcone de ICONS8\n\r\r","permalink":"https://devmedeiros.com/pt/post/2022-04-29-ux-power-bi-dashboards/","summary":"O que é UX/UI? UX é a sigla em inglês para Experiência de Usuário, é um conceito recente que fala sobre tomar decisões de design pensando na experiência do usuário final. O designer de UX precisa se preocupar se seu produto é fácil de usar e intuitivo, fazendo mudanças nele sempre que necessário para se adequar as necessidades do usuário.\nUI, do inglês, significa Interface do Usuário. É tudo aquilo que está envolvido na interação do usuário e o produto.","title":"UX/UI em Dashboards de Business Intelligence"},{"content":"O que é o p-valor? Em estatística temos os testes de hipóteses, que são feitos para tomar uma decisão, de rejeitar ou não rejeitar a hipótese nula. Alguns exemplos de teste de hipótese são: Neyman-Pearson, Shapiro-Wilk, T de Student, entre outros.\nTodos testes de hipóteses possuem uma estatística de teste específico dele. E essa estatística é utilizada para avaliar o teste, mas essa tarefa pode ser cansativa até com o uso de computadores, pois a maioria dos softwares não devolvem como resposta a estatística de comparação, apenas a estatística amostral. Nesse caso o p-valor vem para facilitar essa comparação, pois ele já é uma representação dessa estatística de teste. Ele representa a probabilidade de se obter uma estatística de teste igual ou mais extrema que a calculada na sua amostra, considerando a hipótese nula como verdadeira.\nIsso facilita, pois sabendo o nível de confiança que você quer testar a sua hipótese basta comparar se o p-valor é menor ou maior que o seu nível de confiança, enquanto que se fosse usar a estatística de teste ainda seria necessário calcular a estatística para cada nível de confiança diferente que você fosse comparar. Então suponha que queira comparar 1%, 5% e 10%, você teria que calcular três estatísticas de teste diferentes para comparar a sua estatística amostral.\nComo usar ele? É muito comum quando estamos aprendendo estatística por conta própria lermos que se o p-valor for menor que 5% rejeitamos a hipótese ou que se for maior \u0026ldquo;aceitamos\u0026rdquo; a hipótese.\nO valor com o qual comparamos o p-valor deve ser definido juntamente com pessoas da área de negócio do que você está trabalhando, é muito comum em alguns setores utilizarem um p-valor muito pequeno como 1% ou até 0,1% e em outros usarem valores maiores de que 5%.\nVeja que um p-valor de 0,02 seria rejeitado se considerarmos α = 1%, mas não seria se α = 5%. Na dúvida sobre qual usar, primeiramente é recomendado tomar essa decisão antes de fazer o teste. Segundo, tenha em mente que um α = 1% vai ter uma confiança de 99% (1-α), enquanto que se fosse 5% seria apenas 95%. Pode parecer que é melhor pegar o valor que lhe dá mais \u0026ldquo;confiança\u0026rdquo;, mas um p-valor muito pequeno pode levar a mais rejeições da sua hipótese.\nA verdade é que os testes de hipóteses só nos dão a informação da rejeição, quando uma hipótese nula não é rejeitada isso quer dizer que não foram encontradas evidências que contradizem o que ela afirma, isso não quer dizer que provamos que ela está correta. Então é preciso tomar muito cuidado ao utilizar o p-valor.\nInterpretando a medida Uma forma de interpretar a medida muito comum é \u0026ldquo;Rejeita-se a hipótese nula, com α% de confiança\u0026rdquo;, no caso de rejeição (em que o p-valor \u0026gt; α) e no caso de não rejeição (p-valor \u0026lt; α) \u0026ldquo;Não foram encontradas evidências suficientes para rejeitar a hipótese nula, com α% de confiança\u0026rdquo;.\n","permalink":"https://devmedeiros.com/pt/post/2022-04-12-comprehending-the-p-value/","summary":"O que é o p-valor? Em estatística temos os testes de hipóteses, que são feitos para tomar uma decisão, de rejeitar ou não rejeitar a hipótese nula. Alguns exemplos de teste de hipótese são: Neyman-Pearson, Shapiro-Wilk, T de Student, entre outros.\nTodos testes de hipóteses possuem uma estatística de teste específico dele. E essa estatística é utilizada para avaliar o teste, mas essa tarefa pode ser cansativa até com o uso de computadores, pois a maioria dos softwares não devolvem como resposta a estatística de comparação, apenas a estatística amostral.","title":"Compreendendo o P-Valor"},{"content":"Tools used: Power BI, Figma, SQL\nCategory: Dashboard\n Este dashboard é o último de três do segundo desafio Alura Challenge BI.\n A Alura Skimo está interessada em analisar seus dados de vendas, para ajudar com isso eu fiz este dashboard. Ele é composto de três páginas. A primeira apresenta um resumo com todas as principais medidas que encontramos no painel, filtrado para mostrar o mês mais recente. Nesta primeira página, você pode parar o cursor do mouse sobre uma medida e isso fará com que apareça um pequeno gráfico com a série histórica com uma linha de tendência.\nSeguindo para a próxima página, nela você pode ver toda a informação sobre os produtos vendidos pela Alura Skimo. Você pode filtrar os dados por sabor de sorvete, tipo de embalagem, categoria, e custo do produto. Ela mostra a informação básica sobre os produtos, junto de um ranque dos produtos que são os mais bem vendidos e dois gráficos que mostram as vendas por sabor e vendas por categoria.\nNa última página, você pode encontrar informações sobre os vendedores da nossa empresa. Ele mostra quando o funcionário entrou para a empresa, a comissão deles, o faturamento e quantas vendas cada um fez, tudo isso no último ano (2018).\nEsse painel foi complexo comparado aos outros dois, pois nosso banco de dados veio de arquivos SQL. Primeiro eu tive que criar o banco de dados e carregar cada arquivo SQL para ele, então eu só tive que carregar o banco para o Power BI. Por fim, toda a limpeza, tratamento e processamento de dados foi feito no próprio Power BI.\nCaso você queira olhar os códigos e arquivos utilizados neste projeto, você pode acessar meu repositório do github.\n","permalink":"https://devmedeiros.com/pt/post/2022-03-08-alura-skimo-powerbi/","summary":"Tools used: Power BI, Figma, SQL\nCategory: Dashboard\n Este dashboard é o último de três do segundo desafio Alura Challenge BI.\n A Alura Skimo está interessada em analisar seus dados de vendas, para ajudar com isso eu fiz este dashboard. Ele é composto de três páginas. A primeira apresenta um resumo com todas as principais medidas que encontramos no painel, filtrado para mostrar o mês mais recente. Nesta primeira página, você pode parar o cursor do mouse sobre uma medida e isso fará com que apareça um pequeno gráfico com a série histórica com uma linha de tendência.","title":"Alura Skimo - Power BI Dashboard"},{"content":"Tools used: Power BI, Google Sheets, Figma\nCategory: Dashboard\n Esse painel é o segundo de três que estou fazendo para o segundo desafio Alura Challenge BI.\n A Alura Food está interessada em expandir seus negócios para o mercado indiano. Para isso, a empresa pediu para calcular medidas que os ajudem a tomarem uma melhor decisão.\nPrimeiramente, eu fiz uma junção dos bancos de dados e limpei eles através do Power BI, traduzi alguns dos textos de inglês para português através da Planilhas Google, e converti o preço das refeições da sua moeda original para o real (moeda brasileira). Por fim, eu usei o Figma para fazer o background, incluindo imagens e títulos.\nNeste projeto, eu optei por usar apenas uma página para mostrar toda a informação pedida, pois eu acredito que isso facilita a análise dos dados.\nA maioria dos restaurantes neste mercado indiano não oferecem entrega online, com apenas 19,21% deles tendo este serviço. A avaliação média dos restaurantes é de 3,72, de um total de 5, essa avaliação também é apresentada em formato textual, com um Muito Bom sendo uma nota acima de 4.\nO preço médio de uma refeição por pessoa é de R$ 39,48 (em torno de USD 7,65). E há 9577 restaurantes diferentes em todo o banco de dados, dos quais 3968, especializam na culinária do norte indiano. Nova Delhi é, de longe, o local mais popular para se abrir um restaurante, com 5473 deles, a segunda cidade é Gurgaon, com 1118 restaurantes.\nCaso você queira olhar os códigos e arquivos utilizados neste projeto, você pode acessar meu repositório do github.\n","permalink":"https://devmedeiros.com/pt/post/2022-02-26-alura-food-powerbi/","summary":"Tools used: Power BI, Google Sheets, Figma\nCategory: Dashboard\n Esse painel é o segundo de três que estou fazendo para o segundo desafio Alura Challenge BI.\n A Alura Food está interessada em expandir seus negócios para o mercado indiano. Para isso, a empresa pediu para calcular medidas que os ajudem a tomarem uma melhor decisão.\nPrimeiramente, eu fiz uma junção dos bancos de dados e limpei eles através do Power BI, traduzi alguns dos textos de inglês para português através da Planilhas Google, e converti o preço das refeições da sua moeda original para o real (moeda brasileira).","title":"Alura Food - Power BI Dashboard"},{"content":"Ferramentas utilizadas: Power BI, Planilhas Google, Figma\nCategoria: Dashboard\n Este painel é o primeiro de três que eu estarei fazendo nas próximas semanas como parte do segundo desafio Alura Challenge BI.\n O objetivo deste painel é ajudar a encontrar a melhor seleção para um filme que será produzido.\nCom isso em mente, eu explorei na primeira aba um pequeno resumo sobre os filmes no banco de dados, com ela você pode ter uma ideia geral dos nossos dados. Na segunda aba é apresentado a nota no IMDB e o Meta Score dos filmes. Eu também criei uma medida que mostra o quanto essas duas avaliações concordam entre si. Uma medida de 100 quer dizer que não concordam nem um pouco e 0 quer dizer concordam completamente, a medida de concordância foi de 9,48.\nNossa terceira aba apresenta informação sobre as estrelas dos filmes, os 10 atores com a maior rentabilidade, e os 10 atores com a maior contagem de filmes.\nA quarta aba apresenta a distribuição da renda bruta pela quantidade de gêneros diferentes que um filme tem. Ela também mostra quantos filmes tem um certo gênero, como por exemplo, Drama é a escolha mais popular para gênero de filme, com 72% dos filmes do banco de dados. Por fim, essa aba também mostra a renda bruta média por gênero.\nA quinta e última aba mostra um pouco de informação sobre a classificação indicativa brasileira e mostra o Meta Score médio para filmes com certificação. Ela também mostra a renda bruta, em média, para cada classificação indicativa.\n ","permalink":"https://devmedeiros.com/pt/post/2022-02-17-alura-films-powerbi/","summary":"Ferramentas utilizadas: Power BI, Planilhas Google, Figma\nCategoria: Dashboard\n Este painel é o primeiro de três que eu estarei fazendo nas próximas semanas como parte do segundo desafio Alura Challenge BI.\n O objetivo deste painel é ajudar a encontrar a melhor seleção para um filme que será produzido.\nCom isso em mente, eu explorei na primeira aba um pequeno resumo sobre os filmes no banco de dados, com ela você pode ter uma ideia geral dos nossos dados.","title":"Alura Films - Power BI Dashboard"},{"content":"O show, apresentado por Tyler Renelle da Depth, oferece uma lista com recursos na qual você pode encontrar todos os livros, cursos, e sites mencionados durante o podcast. É um ótimo podcast para quem está aprendendo sobre aprendizado de máquina, podendo ser útil para iniciantes, entusiastas, ou para alguém que está procurando se aprofundar ainda mais no tópico. Desde 2021 o show está sendo renovado para atualizar o conteúdo.\nO show começa falando sobre o que é ciência de dados e como ela se relaciona com aprendizado de máquina e inteligência artificial. Ele também fala sobre as primeiras tentativas em criar IA, com alguns exemplos vindos desde o século 13.\nEu gosto que o show fala sobre conceitos de aprendizado de máquina de uma forma diferente da qual eu estou acostumada. Quando pessoas falam sobre aprendizado de máquina, eu, como Estatística, sempre senti que entendia sobre o que as pessoas estavam falando, exceto que eu não conhecia algumas palavras chaves que elas usavam. Por exemplo, o que engenheiros de aprendizado de máquina chamam de features eu aprendi como variável, então eu ficava confusa quando conversava com amigos sobre aprendizado de máquina quando eles tinham um antecedente diferente do meu (ciência da computação, por exemplo). Esse é um dos motivos que faz eu gostar tanto do podcast, ele fala em ricos detalhes sobre cada conceito de aprendizado de máquina, então se ele fala sobre algo que eu conheço por outro nome eu consigo fazer a conexão.\n","permalink":"https://devmedeiros.com/pt/post/2022-01-24-podcast-review-mlg/","summary":"O show, apresentado por Tyler Renelle da Depth, oferece uma lista com recursos na qual você pode encontrar todos os livros, cursos, e sites mencionados durante o podcast. É um ótimo podcast para quem está aprendendo sobre aprendizado de máquina, podendo ser útil para iniciantes, entusiastas, ou para alguém que está procurando se aprofundar ainda mais no tópico. Desde 2021 o show está sendo renovado para atualizar o conteúdo.\nO show começa falando sobre o que é ciência de dados e como ela se relaciona com aprendizado de máquina e inteligência artificial.","title":"Review do Podcast - Machine Learning Guide"},{"content":"Recentemente eu terminei um curso na Alura chamado Python para Data Science e eu quero colocar o que eu aprendi em prática, para isso eu vou fazer uma análise descritiva nesse banco de dados Amazon Top 50 Bestselling Books 2009 - 2019. Nele há 550 livros e eles foram categorizados como fiction (ficção) e non-fiction (não ficção) pelo Goodreads. Todo o código pode ser visto aqui.\nEu comecei olhando as cinco primeiras observações do banco de dados.\n   Name Author User Rating Reviews Price Year Genre     10-Day Green Smoothie Cleanse JJ Smith 4.7 17350 8 2016 Non Fiction   11/22/63: A Novel Stephen King 4.6 2052 22 2011 Fiction   12 Rules for Life: An Antidote to Chaos Jordan B. Peterson 4.7 18979 15 2018 Non Fiction   1984 (Signet Classics) George Orwell 4.7 21424 6 2017 Fiction   5,000 Awesome Facts (About Everything!) (Natio\u0026hellip; National Geographic Kids 4.8 7665 12 2019 Non Fiction    Aqui é possível ver que os dados tem o Year (ano) em que o livro estava no top 50 de mais vendidos, seu Price (preço), a média dos User Rating (avaliação dos usuários), total de Reviews (avaliações), Author (autor), Name (nome do livro) e por fim, Genre (gênero).\nNão há valores nulos no banco de dados. E dos 550 livros há 248 autores diferentes, então vamos ver quais autores possuem mais livros no top 50 dos mais vendidos neste período.\n   Autor Número de livros     Jeff Kinney 12   Gary Chapman 11   Rick Riordan 11   Suzanne Collins 11   American Psychological Association 10   Dr. Seuss 9   Gallup 9   Rob Elliott 8   Stephen R. Covey 7   Stephenie Meyer 7   Dav Pilkey 7   Bill O\u0026rsquo;Reilly 7   Eric Carle 7    O autor com mais livros no top 50 foi Jeff Kinney, empatado em segundo, com 11 livros, foi Gary Chapman, Rick Riordan, e Suzanne Collins. Empatado em 9º, está Stephen R. Covey, Stephenie Meyer, Dav Pilkey, Bill O\u0026rsquo;Reilly, e Eric Carle, com 7 livros cada.\nCom o gráfico de violino podemos ver como está concentrado a avaliação dos usuários e como os dados são compostos de livros bestsellers faz sentido que a avaliação dos usuários está em sua maioria concentrada em torno de 4.5 e 4.75.\nEsse boxplot da quantidade de avaliações por ano mostra que a variabilidade aumentou através dos anos, tendo o seu pico em 2014 e gradualmente estabilizando. Podemos ver também que nos primeiros anos, 2010 e 2011, havia mais outliers nos dados.\n   Gênero Avaliação do Usuário Preço     Ficção 4.65 10.85   Não Ficção 4.60 14.84    A avaliação média do usuário por gênero parece ser semelhante, com apenas 0.05 de diferença, mas o preço já apresenta uma diferença maior, 10.85 para ficção e 14.84 para não ficção. Para termos certezas de que essas diferenças são estatisticamente significantes, eu vou utilizar o teste de Mann-Whitney.\nA hipótese nula do teste de Mann-Whitney é de que as amostras possuem a mesma distribuição, e em ambos os casos, nós rejeitamos a hipótese nula com 95% de confiança. O p-valor para os dados do preço foi de 8.34e-08 e o p-valor para a avaliação do usuário foi de 1.495e-07.\nPara mostrar visualmente quão diferente as suas distribuição são, podemos olhar para os seguintes gráficos.\nA distribuição para os preços de livros de ficção é fortemente inclinados para a esquerda e consistentemente diminuem a medida que o preço aumenta. Enquanto que os livros de ficção começam altos e se tornam ainda mais altos, com 120 e quase 140 ocorrências nas duas primeiras categorias, então ele rapidamente diminui.\nA distribuição para a avaliação do usuário do gênero de ficção lentamente aumenta, tendo seu pico próximo de 4.8. E a distribuição para o gênero de não ficção tem seu pico logo após 4.6.\n","permalink":"https://devmedeiros.com/pt/post/2021-12-28-amazon-top-50-books/","summary":"Recentemente eu terminei um curso na Alura chamado Python para Data Science e eu quero colocar o que eu aprendi em prática, para isso eu vou fazer uma análise descritiva nesse banco de dados Amazon Top 50 Bestselling Books 2009 - 2019. Nele há 550 livros e eles foram categorizados como fiction (ficção) e non-fiction (não ficção) pelo Goodreads. Todo o código pode ser visto aqui.\nEu comecei olhando as cinco primeiras observações do banco de dados.","title":"Análise Descritiva do Top 50 Livros Bestsellers da Amazon 2009 - 2019"},{"content":"Introdução Eu estou aprendendo visualização de dados no Python e eu me vejo como alguém que aprende fazendo, por isso eu vou fazer alguns gráficos simples usando o pacote seaborn que poderão ser utilizados como referência sempre que precisar refrescar a memória.\nPrimeiramente é necessários que os pacotes estejam propriamente importados, após isso eu carrego o banco de dados iris.\nimport pandas as pd import seaborn as sns import matplotlib.pyplot as plt  url = \u0026#34;https://git.io/JXciW\u0026#34;  iris = pd.read_csv(url) Caso não esteja familiarizado com o banco de dados iris, veja as cinco primeiras linhas dele a seguir:\n   sepal_length sepal_width petal_length petal_width species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa    Gráfico de barras Criar um simples gráfico de barras.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris) Fazendo um gráfico de barras horizontais.\nsns.barplot(x=\u0026#34;petal_width\u0026#34;, y=\u0026#34;species\u0026#34;, data=iris) Ordem das barras personalizada.\nsns.barplot(  x=\u0026#34;species\u0026#34;,  y=\u0026#34;petal_width\u0026#34;,  data=iris,  order=[\u0026#34;virginica\u0026#34;, \u0026#34;setosa\u0026#34;, \u0026#34;versicolor\u0026#34;]) Acrescentar limites para as barras de erro.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, capsize=.2) Gráfico de barra sem barras de erro.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, ci=None) Gráfico de dispersão Um gráfico de dispersão simples.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris) Acrescentando grupos no gráfico de dispersão.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, hue=\u0026#34;species\u0026#34;) Acrescentando grupos e escalando os pontos de um gráfico de dispersão.\nsns.scatterplot(  x=\u0026#34;sepal_width\u0026#34;,  y=\u0026#34;petal_width\u0026#34;,  data=iris,  hue=\u0026#34;sepal_length\u0026#34;,  size=\u0026#34;sepal_length\u0026#34;) Legenda e Eixos Para mover a legenda do gráfico para fora da área de plotagem, você pode utilizar bbox_to_anchor = (1,1), loc=2. O gráfico a seguir possui um titulo personalizado, um novo título para o eixo x e pro eixo y.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, hue=\u0026#34;species\u0026#34;) plt.legend(  title=\u0026#34;Species\u0026#34;,  bbox_to_anchor = (1,1),  loc=2) plt.xlabel(\u0026#34;Sepal Width\u0026#34;) plt.ylabel(\u0026#34;Petal Width\u0026#34;) plt.title(\u0026#34;Sepal Width x Petal Width\u0026#34;) ","permalink":"https://devmedeiros.com/pt/post/2021-11-07-seaborn-package-guide/","summary":"Introdução Eu estou aprendendo visualização de dados no Python e eu me vejo como alguém que aprende fazendo, por isso eu vou fazer alguns gráficos simples usando o pacote seaborn que poderão ser utilizados como referência sempre que precisar refrescar a memória.\nPrimeiramente é necessários que os pacotes estejam propriamente importados, após isso eu carrego o banco de dados iris.\nimport pandas as pd import seaborn as sns import matplotlib.pyplot as plt  url = \u0026#34;https://git.","title":"Guia do Pacote de Python seaborn"},{"content":"O pacote data.table é um dos pacotes de manipulação de dados mais rápido, atualmente ele é mais rápido até que o pandas e dplyr 1. A sintaxe de um data.table é dt[i, j, by], em que:\n i é utilizado para amostrar linhas j é utilizado para amostrar colunas by é utilizado para amostrar grupos, igual ao GROUP BY do SQL  Você pode ler em voz alta como2:\n Pegue dt, amostra/reordene as linhas usando i, então calcule j, agrupando por by.\n Um data.table também é um data.frame e todas as manipulações de dados básicas que você pode usar em um data.frame se aplica a um data.table. Como ncol(), nrow(), names(), summary(). Mas ele não para por aí, por exemplo data.table possui uma variável especial .N que é um integral que contains os números das linhas no grupo. Se você usar dt[.N] você verá a última linha do seu data.table.\nOutra coisa interessante do data.table é que se você quiser filtrar/amostrar uma coluna, você não precisa utilizar df$x[df$x == 1] você pode simplesmente usar dt[x == 1] o que torna o seu código mais limpo e fácil de ler.\nVocê também tem a possibilidade de utilizar operadores especiais como: %like%, %in% e %between%. Estes operadores funcionam como operadores de SQL, LIKE, IN, e BETWEEN, respectivamente.\nSe você está familiarizado com SQL tem uma coisa que esse pacote oferece que irá chamar a sua atenção. No inglês se chama chaining (acorrentar), que permite a você a fazer uma sequência de operações em um data.table, você apenas precisa utilizar dt[][] e acorrentar múltiplas operações com \u0026ldquo;[]\u0026rdquo;.\nMas este não são todos os operadores, com := você pode alterar dados sem fazer uma nova cópia na memória.\nCaso queira começar a usar o pacote eu sugiro que use a cheatsheet (folha de referência/colinha). É extramente útil caso já tenha um conhecimento básico sobre data.frames.\n  https://h2oai.github.io/db-benchmark/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://devmedeiros.com/pt/post/2021-10-27-data-table/","summary":"O pacote data.table é um dos pacotes de manipulação de dados mais rápido, atualmente ele é mais rápido até que o pandas e dplyr 1. A sintaxe de um data.table é dt[i, j, by], em que:\n i é utilizado para amostrar linhas j é utilizado para amostrar colunas by é utilizado para amostrar grupos, igual ao GROUP BY do SQL  Você pode ler em voz alta como2:\n Pegue dt, amostra/reordene as linhas usando i, então calcule j, agrupando por by.","title":"Uma Visão Geral Sobre o Pacote data.table do R"},{"content":"Ferramentas utilizadas: R, ggplot, Shiny\nCategoria: Simulação\n O meu objetivo com este projeto é de simular o ambiente de um jogo de 21, também conhecido como blackjack. Assim, eu decidi fazer diversas funções para emular o comportamento do dealer, de um jogador iniciante, um jogador cauteloso e um estrategista. Com esse conjunto de funções você pode rodar um jogo com p jogadores, d baralhos e quaisquer combinações de arquétipos de jogadores. Além disso, também pode rodar o jogo n vezes.\nEu também fiz uma aplicação shiny para demonstrar como a simulação funciona. No aplicativo, você é limitado no número de jogadores, mas caso queira rodar o código com mais jogadores eu sugiro que olhe o respositório do GitHub. Nele você encontra as regras consideradas para a simulação e o código completo.\nCaso seja familiar com a linguagem de programação R, você também pode rodar o aplicativo localmente, basta carregar a biblioteca do shiny library(shiny) e rodar o código runGitHub(\u0026quot;blackjack-simulation\u0026quot;, \u0026quot;devmedeiros\u0026quot;, ref = \u0026quot;main\u0026quot;).\nO app é composto de uma barra lateral com um espaço para escolher os arquétipos, o número de baralhos a ser usados e quantas rodadas você quer simular. Dependendo de quantas rodadas você escolher a simulação pode ficar mais lenta, pois a simulação roda de acordo com as suas escolhas todas vez que clica no botão RUN SIMULATION RUN.\nNa aba plot, nota-se a evolução da taxa de perda através das rodadas.\n1 quer dizer que o jogador perdeu aquela rodada e um 0 quer dizer que ele ganhou.\nA aba game setup mostra todas as cartas distribuídas na simulação, cada carta foi entregue da esquerda para a direita e uma célula em branco quer dizer que o jogador não pediu pra receber outra carta (hit, bate).\nPor fim, a aba lose rate mostra os mesmo dados da aba plot, mas em formato de tabela. Isso é útil quando se quer analisar como uma estratégia foi melhor do que outra.\n","permalink":"https://devmedeiros.com/pt/post/2021-10-24-blackjack-simulation/","summary":"\u003cp\u003e\u003cstrong\u003eFerramentas utilizadas:\u003c/strong\u003e R, ggplot, Shiny\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCategoria:\u003c/strong\u003e Simulação\u003c/p\u003e\n\u003chr\u003e","title":"Simulação de 21"},{"content":"Eu quero fazer uma análise de sentimentos usando o R como uma forma de aprender. Com isso em mente começamos carregando todos os pacotes que iremos utilizar.\nlibrary(readr) library(dplyr) library(tidytext) library(tokenizers) library(stopwords) library(ggplot2) Então precisamos carregar nosso banco de dados. Esses dados são do Kaggle Fake and real news dataset.\nFake \u0026lt;- read_csv(\u0026#39;~/fakenews/Fake.csv\u0026#39;) True \u0026lt;- read.csv(\u0026#39;~/fakenews/True.csv\u0026#39;) Eu quero unir ambos os dados, mas antes é preciso criar uma nova columa que irá informar de onde os dados vieram.\nFake$news \u0026lt;- \u0026#39;fake\u0026#39; True$news \u0026lt;- \u0026#39;real\u0026#39;  data \u0026lt;- rbind(Fake,True) Agora podemos iniciar a limpeza dos dados. Neste primeiro momento, fazemos os tokens nas variáveis title e text. Em seguida iremos remover as stopwords (palavras redundantes) de acordo com a fonte snowball do pacote stopwords.\ntitle \u0026lt;- tibble(news = data$news, text = data$title)  corpus \u0026lt;- tibble(news = data$news, corpus = data$text)  tidy_title \u0026lt;- title %\u0026gt;%  unnest_tokens(word, text, token = \u0026#39;words\u0026#39;) %\u0026gt;%  filter(!(word %in% stopwords(source = \u0026#39;snowball\u0026#39;)))  tidy_corpus \u0026lt;- corpus %\u0026gt;%  unnest_tokens(word, corpus, token = \u0026#39;words\u0026#39;) %\u0026gt;%  filter(!(word %in% stopwords(source = \u0026#34;snowball\u0026#34;))) Com os dados limpos podemos selecionar as dez palavras mais frequentes dos títulos das noticias, separado por grupo real ou falso.\np0 \u0026lt;- tidy_title %\u0026gt;%  group_by(news, word) %\u0026gt;%  summarise(n = n()) %\u0026gt;%  arrange(desc(n)) %\u0026gt;%  slice(1:10) Títulos de notícias falsas mencionam muito mais video e trump, 8477 e 7874, respectivamente. Já no caso de títulos de notícias reais, trump também é uma das palavras mais mencionadas, aparecendo em primeiro com 4883 aparições, seguido por u.s com 4187 e says com 2981.\nAgora iremos preparar os dados para a análise de sentimento. Eu estou interessada em classificar os dados em sentimentos de alegria, raiva, medo ou surpresa, por exemplo. Então eu iriei utilizar o os dados de nrc Saif Mohammad and Peter Turney.\np1 \u0026lt;- tidy_title %\u0026gt;%  inner_join(get_sentiments(\u0026#39;nrc\u0026#39;)) %\u0026gt;%  group_by(sentiment, news) %\u0026gt;%  summarise(n = n()) %\u0026gt;%  mutate(prop = n/sum(n)) Disgust (nojo) aparenta ser o sentimento mais comum envolvendo títulos de notícias falsas, enquanto que trust (confiança) é o menor, mesmo que ainda seja maior que 50%. Em geral, títulos de notícias falsas aparentam ter mais \u0026ldquo;sentimento\u0026rdquo; do que títulos de notícias reais, neste banco de dados. Isso vale até para sentimentos positivos como joy (alegria) e surprise (surpresa).\np2 \u0026lt;- tidy_corpus %\u0026gt;% inner_join(get_sentiments(\u0026#39;nrc\u0026#39;)) %\u0026gt;% group_by(sentiment, news) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n/sum(n)) Para o corpo das notícias reais pode-se notas que os mesmos sentimentos são prevalentes, mas a proporção é menor comparado ao título. Um artigo de notícias falsas perde confiança (trust) quando o leitor lê o corpo do artigo. Ele também se torna menos negativo (negative) e apresenta menos medo (fear)\nUma melhoria que poderia ser feito aqui é tentar construir nosso próprio dicionário de palavras redundantes (stopwords) e alterar a forma que a toneização foi feita. Pois houveram momentos em que trump e trump\u0026rsquo;s não corresponderam a mesma coisa e se estes dados tivessem sido usados para treinar um modelo isso poderia se tornar um problema.\n","permalink":"https://devmedeiros.com/pt/post/2021-10-12-fakenews-sentiment/","summary":"Eu quero fazer uma análise de sentimentos usando o R como uma forma de aprender. Com isso em mente começamos carregando todos os pacotes que iremos utilizar.\nlibrary(readr) library(dplyr) library(tidytext) library(tokenizers) library(stopwords) library(ggplot2) Então precisamos carregar nosso banco de dados. Esses dados são do Kaggle Fake and real news dataset.\nFake \u0026lt;- read_csv(\u0026#39;~/fakenews/Fake.csv\u0026#39;) True \u0026lt;- read.csv(\u0026#39;~/fakenews/True.csv\u0026#39;) Eu quero unir ambos os dados, mas antes é preciso criar uma nova columa que irá informar de onde os dados vieram.","title":"Análise de Sentimentos de Notícias Falsas vs Notícias Reais"},{"content":"Oi! Meu nome é Jaqueline Medeiros e eu sou uma Cientista de Dados. Eu sou formada em Estatística e a maioria da minha experiência é em análise e visualização de dados. Mesmo assim, eu tenho me interessado em engenharia de dados, tenho participado em projetos envolvendo esse ramo da ciência de dados. Atualmente estou trabalhando em implementar PySpark e Apache Hop para tornar o tratamento dos dados mais rápido e eficiente.\nApesar de querer focar em engenharia de dados, eu ainda estou interessada em aprendizado de máquina, análise de dados, e outras coisas sob o domínio de ciência de dados. Então eu continuarei postando sobre diversos assuntos de ciência de dados.\nVocê pode me encontrar em:\n Linkedin: medeiros-jaqueline Github: devmedeiros  Curriculum Vitae Cientista de dados que compõe o Laboratório de Inovações do Tribunal Regional Eleitoral de Goiás. No meu dia-a-dia eu trabalho com processos de tratamento e limpeza de dados, ingestão de dados de diversas fontes, criação de views e aplicações de Business Intelligence.\nFormação Acadêmica Universidade Federal de Goiás - UFG - Goiânia, GO\nEspecialização em Banco de Dados com Big Data (Abr 2020 - presente)\nUniversidade Federal de Goiás - UFG - Goiânia, GO\nBacharel em Estatística (Concluído em Dezembro de 2020)\n  Disciplinas: Regressão Linear, Regressão Logística, Séries Temporais, Estatística Não Paramétrica, Inferência Estatística, Análise Multivariada, e Probabilidade.   Experiência Profissional Tribunal Regional Eleitoral de Goiás - Goiânia, GO\nEstatístico - Cientista de Dados (Jun 2020 – presente)\n  Utilizo expertise analítica e técnica para gerar insights que ajudam a melhorar a governança, produtividade e transparência do tribunal, alavancando sua pontuação no Prêmio CNJ de Qualidade de 70,28%, em 2020, para 80,72% em 2021. Identificar gargalos no processo eleitoral. Ingestão de dados de diversas fontes usando uma combinação de SQL, R e Python. Gerando views para serem usados em painéis de Power BI.   Projetos e Cargos na Graduação GRUPOM Consultoria e Pesquisa - Goiânia, GO\nEstágio - Pesquisador de Opinião (Abr 2019 – May 2020)\n  Planejamento e implementação de pesquisas eleitorais, de opinião e mercado. Tratamento e limpeza de dados usando Excel e R. Elaboração e apresentação de relatórios estáticos e interativos de Business Intelligence.   3ª Monitoria\nEstatística Computacional I (1º Semestre 2018)\n  Auxiliar a professora nas aulas, montar gabaritos para listas de exercícios e resoluções de exercícios da professora. Ajudar alunos da disciplina com o conteúdo apresentado em aula. Aulas de resoluções de exercícios utilizando o software R.   Iniciação Científica PIVIC\nEstudo orientado sobre Cartas de Controle (2º Semestre de 2016 - 1º Semestre 2017)\n  Análise exploratória através de cartas de controle das taxas inflacionárias no Brasil durante o período de 2002 - 2016.   2ª Mentoria\nProbabilidade e Estatística (2º Semestre 2015)\n  Confeccionar gabaritos para listas de exercícios e resoluções de exercícios da disciplina. Sanar dúvidas dos alunos da disciplina sobre o conteúdo ministrado em aula.   1ª Mentoria\nProbabilidade e Estatística (1º Semestre 2015)\n  Montar gabaritos para listas de exercícios e resoluções de exercícios da disciplina. Assessorar alunos da disciplina com dúvidas sobre o conteúdo ministrado em aula.   Especialidades   Análise Estatística e Preparação de Dados Modelagem Estatística e Machine Learning Linguagens de programação em Python e R Metodologias Ágeis Linguagens de query em SQL e Power Query Desenvolvimento de painéis interativos de BI (usando Power BI)   Cursos e Certificados   The Complete SQL Bootcamp: Go From Zero to Hero Python para Data Science Business Intelligence: Introdução à Inteligência Empresarial Fundamentos de Agilidade: Seus Primeiros Passos para a Transformação Ágil Linux I: Conhecendo e Utilizando o Terminal   Uma versão em PDF está disponível aqui.\n","permalink":"https://devmedeiros.com/pt/about/","summary":"about","title":"Sobre"}]