[{"content":"Ferramentas utilizadas: Python, seaborn, scikit-learn, imbalanced-learn\nCategoria: An√°lise de Dados, Aprendizado de M√°quina\nEu fui desafiada a tomar o papel da nova cientista de dados na Alura Voz. Essa empresa fict√≠cia √© do ramo de telecomunica√ß√£o e precisa reduzir sua taxa de evas√£o de clientes.\nEsse desafio √© dividido em quatro semanas. Para a primeira semana o objetivo √© tratar o banco de dados proveniente de uma API. Em seguida, precisamos identificar clientes que s√£o mais propensos a deixar a empresa, usando explora√ß√£o e an√°lise de dados. E ent√£o, na terceira semana, n√≥s usamos modelos de machine learning para prever a taxa de evas√£o da Alura Voz. A √∫ltima semana √© para expor o que fizemos durante o desafio e construir nosso portfolio. Caso esteja interessado em ver o c√≥digo, ele est√° dispon√≠vel no meu reposit√≥rio do GitHub.\nPrimeira Semana Lendo o Banco de Dados O banco de dados foi disponibilizado no formato JSON e num primeiro momento aparenta ser um data frame normal.\nEntretanto, como pode ser observado, customer, phone, internet, e account s√£o suas pr√≥prias tabelas. Ent√£o eu normalizei elas separadamente e depois simplesmente concatenei todas essas tabelas em uma.\nDados Faltantes A primeira vez que eu procurei por dados faltantes nessa base nenhum foi encontrado, mas a medida que eu explorei os dados eu percebi que havia espa√ßos em branco e vazios n√£o sendo contados como NaN. Ent√£o eu corrigi isso e descobri que havia 224 dados faltantes para a vari√°vel Churn e 11 para Charges.Total.\nEu decidi desconsiderar os dados faltantes da vari√°vel Churn, pois este ser√° nosso objeto de estudo e n√£o h√° sentido em estudar algo que n√£o existe. No caso dos dados faltantes de Charges.Total, eu imagino que representa um cliente que n√£o pagou nada ainda, pois todos eles possuem 0 meses de contrato, ou seja, eles acabaram de se tornar clientes, ent√£o eu simplesmente substitui o valor faltante por 0.\nCodifica√ß√£o de Vari√°veis A vari√°vel SeniorCitizen foi a √∫nica que veio com 0 e 1 ao inv√©s de Yes e No. Por hora eu irei trocar esses valores por \u0026ldquo;yes\u0026rdquo; e \u0026ldquo;no\u0026rdquo;, pois isto torna a an√°lise mais simples de ser lida.\nCharges.Monthly e Charges.Total foram renomeadas para perderem o ponto, pois isto atrapalha na hora de lidar com elas no python.\nSegunda Semana An√°lise de Dados No primeiro gr√°fico podemos ver o qu√£o desbalanceado nosso banco de dados √©. H√° mais de 5000 clientes que n√£o deixaram a empresa e um pouco menos de 2000 que deixaram.\nEu experimentei usar t√©cnicas de sobreamostragem (oversampling) para lidar com esse deslanceamento, mas isto fez com que os modelos de aprendizado de m√°quina tivessem uma performance pior. E subamostragem (undersampling) n√£o √© uma op√ß√£o com um banco de dados desse tamanho, ent√£o eu decidi deixar do jeito que est√°, e quando for hora de separar os dados de treino e teste eu irei estratificar o banco de acordo com a vari√°vel Churn.\nEu tamb√©m gerei 16 gr√°ficos para todas as vari√°veis discretas, para ver todos os gr√°ficos olhe este notebook. O objetivo √© ver se havia algum comportamento que fazia alguns cliente mais propensos a deixar a empresa. √â claro que todas, exceto por gender, parecem ter algum papel em determinar se um cliente vai ou n√£o deixar a empresa. Mais especificamente forma de pagamento, contratos, backup online, suporte t√©cnico, e servi√ßo de internet.\nNo gr√°fico de tenure, eu decidi fazer gr√°ficos de distribui√ß√£o dos meses de contrato do cliente, um gr√°fico para os cliente que n√£o evadiram e um para os que evadiram. Podemos ver que clientes que evadiram o fizeram no in√≠cio do seu tempo na empresa.\nA cobran√ßa mensal m√©dia para os cliente que n√£o evadiram √© de 61,27 unidades monet√°ria, enquanto que clientes que evadiram pagam 74,44. Isso provavelmente √© por conta do tipo de contrato que esses tipo de clintes preferem, mas de qualquer forma √© senso comum que pre√ßos altos afastam clientes.\nO Perfil de Evas√£o Considerando tudo que eu pude observar atrav√©s de gr√°ficos e medidas, eu fiz um perfil de clientes que s√£o mais propensos a evadir a empresa.\nClientes novos s√£o mais propensos a evadir do que clientes antigos.\nClientes com poucos servi√ßos e produtos tendem a deixar a empresa. Se eles n√£o est√£o presos a um contrato mais longo eles aparentam ser mais propensos a abandonar a empresa.\nSobre os meios de pagamentos, cliente que evadem possuem uma prefer√™ncia forte por cheques eletr√¥nicos e usualmente gastam 13,17 unidades monet√°rias a mais que a m√©dia de clientes que n√£o deixaram a empresa.\nTerceira Semana Preparando o Banco de Dados Damos in√≠cio fazendo vari√°veis dummies, de forma que teremos n-1 dummies para n vari√°veis. Ent√£o fazemos uma matriz de correla√ß√£o para avaliar a correla√ß√£o das nossas vari√°veis.\nPodemos ver que a vari√°vel InternetService_No possui correla√ß√µes altas com diversas outras vari√°veis, isso se d√° porque as outras vari√°veis depende do cliente ter ou n√£o acesso a internet. Ent√£o irei tirar essas vari√°veis dependentes do modelo. A mesma coisa ocorre com PhoneService_Yes.\ntenure e ChargesTotal tamb√©m possuem uma alta correla√ß√£o, mas eu testei rodar os modelos sem uma das duas ou ambas e os modelos tiveram uma performance pior e levaram mais tempo para covergirem, ent√£o eu decidi manter elas no modelo, e elas s√£o relevantes para o problema.\nAp√≥s retirar essas vari√°veis eu termino de preparar o banco de dados com uma normaliza√ß√£o das vari√°veis num√©ricas, ChargesTotal e tenure.\nBanco de Dados de Teste e Treino Eu dividi o banco de dados em treino e teste, 20% para teste e o resto para treino. Eu estratifiquei os dados de acordo com a vari√°vel Churn e embaralhei os dados antes de separar. A mesma divis√£o de dados √© usada em todos os modelos. Ap√≥s separar os dados eu decidi fazer uma sobreamostragem (oversampling) dos dados de teste usando SMOTE1, pois os dados s√£o muito desbalanceados. O motivo de eu usar essa t√©cnica apenas nos dados de teste √© que eu n√£o quero ter um resultado viesado, se eu sobreamostrar todo o banco de dados isso quer dizer que eu vou testar meu modelo no mesmo dado que eu o treinei, e este n√£o √© meu objetivo.\nAvalia√ß√£o dos Modelos Eu vou utilizar um classificador dummy para ter uma base para a medida de acur√°cia, e eu tamb√©m vou utilizar as m√©tricas: precision (precis√£o), recall (recorda√ß√£o) and f1 score (medida f1)2. Apesar de que o modelo dummy n√£o ter valor para essas m√©tricas eu vou manter ele para comparar a melhora dos modelos.\nModelo Base O modelo base foi feito atrav√©s de um classificador dummy, basicamente ele diz que todos os clientes se comportam da mesma forma. Neste caso o modelo chutou que nenhum cliente iria deixar a empresa. Usando essa abordagem o modelo base obteve uma acur√°cia de 0,73456.\nA seguir todos os modelos ter√£o a mesma semente aleat√≥ria (random state).\nModelo 1 - Florestas Aleat√≥rias Eu inicio usando uma busca no grid com valida√ß√£o cruzada (grid search with cross-validation) para encontrar os melhores par√¢metros dentro de uma sele√ß√£o de op√ß√µes utilizando o recall como estrat√©gia para avaliar a performance. O melhor modelo encontrado pela busca foi:\nRandomForestClassifier(criterion=\u0026#39;entropy\u0026#39;, max_depth=5, max_leaf_nodes=70, random_state=22) Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,72534 Medida Precision: 0,48922 Medida Recall: 0,78877 Medida F1: 0,60389 Modelo 2 - Classifica√ß√£o de Vetores de Suporte Linear Neste modelo eu usei os par√¢metros padr√µes e aumentei o teto para o m√°ximo de itera√ß√µes para 900000.\nLinearSVC(max_iter=900000, random_state=22) Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,71966 Medida Precision: 0,48217 Medida Recall: 0,75936 Medida F1: 0,58982 Modelo 3 - Rede Neural Multicamada Perceptron Aqui eu fixei o solucionador LBFGS, pois de acordo com a documenta√ß√£o do scikit-learn ele tem uma performance melhor em banco de dados pequenos 3, e tamb√©m fiz uma busca no grid com valida√ß√£o cruzada para encontrar o melhor tamanho da camada oculta. O melhor modelo foi:\nMLPClassifier(hidden_layer_sizes=(1,), max_iter=9999, random_state=22, solver=\u0026#39;lbfgs\u0026#39;) Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,72818 Medida Precision: 0,49133 Medida Recall: 0,68182 Medida F1: 0,57111 Conclus√£o Ap√≥s rodar os tr√™s modelos, todos usando o mesmo random_state. Eu encontrei as seguintes medidas de acur√°cia e melhorias no desempenho (comparado com o modelo base):\nNo fim, a Floresta Aleat√≥ria teve as melhores m√©tricas. Este modelo consegue recordar uma grande parte dos clientes que evadem corretamente, ainda n√£o √© perfeito, mas j√° √© um ponto de partida. A medida de acur√°cia n√£o √© t√£o alta como eu gostaria, mas para este problema em particular o objetivo √© impedir os clientes de deixar a empresa e √© melhor utilizar recursos para manter um cliente que n√£o vai deixar a empresa do que n√£o fazer nada.\nNo fim, eu gostei desse desafio, pois √© raro eu praticar aprendizado de m√°quina, mas gra√ßas ao desafio eu tive a oportunidade de fazer um pequeno projeto nessa √°rea que √© t√£o importante e relevante. Essa foi a minha primeira vez trabalhando com redes neurais e ajuste de hiperpar√¢metros, e tenho certeza que na pr√≥xima vez terei resultados ainda melhores.\nimbalanced-learn documentation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAccuracy, Precision, Recall or F1? - Koo Ping Shung\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nscikit-learn documentation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/","summary":"\u003cp\u003e\u003cstrong\u003eFerramentas utilizadas:\u003c/strong\u003e Python, seaborn, scikit-learn, imbalanced-learn\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCategoria:\u003c/strong\u003e An√°lise de Dados, Aprendizado de M√°quina\u003c/p\u003e\n\u003chr\u003e","title":"Data Science Challenge - Churn Rate"},{"content":"O que √© UX/UI? UX √© a sigla em ingl√™s para Experi√™ncia de Usu√°rio, √© um conceito recente que fala sobre tomar decis√µes de design pensando na experi√™ncia do usu√°rio final. O designer de UX precisa se preocupar se seu produto √© f√°cil de usar e intuitivo, fazendo mudan√ßas nele sempre que necess√°rio para se adequar as necessidades do usu√°rio.\nUI, do ingl√™s, significa Interface do Usu√°rio. √â tudo aquilo que est√° envolvido na intera√ß√£o do usu√°rio e o produto. O designer de UI √© respons√°vel por desenvolver interfaces, n√£o limitado apenas aos aspectos visuais, tamb√©m √© importante garantir que sejam funcionais, us√°veis, e que em geral, contribuem para uma boa experi√™ncia do usu√°rio.\nComo Melhorar a Experi√™ncia dos Pain√©is de BI? Muitos pessoas veem os pain√©is de BI como p√°ginas de web e isso traz algumas expectativas de uso. Por exemplo, a maioria dos sites que possuem algum sistema de navega√ß√£o usam um menu superior com bot√µes, um menu lateral (mais comum no Brasil sendo na esquerda, mas em alguns pa√≠ses √© na direita) ou um menu sandu√≠che (aquele que clicamos no bot√£o e aparece as op√ß√µes).\nJaqueline Medeiros - Todos os direitos reservados\nCom isso uma grande parcela das pessoas que utilizam os pain√©is esperam encontrar bot√µes de navega√ß√£o e segmenta√ß√£o (filtro) de dados nestes locais, al√©m de outras informa√ß√µes como logo e t√≠tulo.\nSegmenta√ß√£o de Dados Tamb√©m comummente chamado de filtro de dados √© uma pe√ßa fundamental de diversos dashboards, seu posicionamento precisa ser definido com cuidado, pois se estiver num lugar que o usu√°rio n√£o espera pode impedir que seu painel seja usado eficientemente, al√©m disso manter um padr√£o visual para todos os seus filtros ajudam as pessoas a reconhecerem mais facilmente o que √© ou n√£o √© um filtro.\nVoc√™ pode e deve usar e experimentar com diversos temas nos seus trabalhos. O que importa, na hora de facilitar para os usu√°rios, √© a consist√™ncia, escolha um modelo de filtro com as cores desejadas e todas as especifica√ß√µes gr√°ficas que s√£o do seu interesse e utilize ela em todos os filtros, pois isso ir√° ajudar as pessoas a baterem o olho e reconhecer que aquilo √© um filtro.\n√â muito comum as pessoas quando est√£o lendo algo pelo computador posicionarem o ponteiro do mouse onde elas est√£o lendo. No caso do Power BI, isso torna mais f√°cil para o usu√°rio encontrar o bot√£o de limpar a segmenta√ß√£o de dados, pois ao passar o mouse no nome do filtro aparece uma borrachinha no lado esquerdo onde fica o nome do filtro. T√° mais se voc√™ usa o Power BI provavelmente j√° sabia disso, mas podemos melhorar isso usando algo que o usu√°rio j√° conhece, que √© a borrachinha, e criar um bot√£o usando a borrachinha como √≠cone e fazer com que esse bot√£o limpe todos os filtros ao mesmo tempo. Caso queira saber como fazer esse bot√£o aqui no f√≥rum do Power BI explica como.\nEssa √© uma caracter√≠stica que pode ter sua import√¢ncia despercebida num primeiro momento, mas algo que ocorre muito √© os usu√°rios do painel n√£o perceberem quais filtros eles usaram ou usarem tantos que s√≥ querem poder limpar a sele√ß√£o de forma mais r√°pida e eficiente, ent√£o esse bot√£o torna o processo muito mais user friendly.\nNavega√ß√£o de P√°gina A navega√ß√£o de p√°ginas nativa do Power BI n√£o √© intuitiva para a maioria das pessoas e em muitas vezes voc√™ pode querer direcionar a navega√ß√£o num fluxo espec√≠fico que facilita o entendimento e contribui para o storytelling planejado. Neste caso temos a op√ß√£o de ocultar todas as abas do relat√≥rio, exceto uma que √© a p√°gina de abertura/inicial. Mas qual a melhor forma de direcionar o usu√°rio para as demais p√°ginas? Bem, isso depende do que voc√™ est√° fazendo. Suponha que seu relat√≥rio seja bem simples, voc√™ tem uma aba de vis√£o geral e outra aba com um detalhamento, um simples bot√£o resolveria o seu problema, mas caso seu relat√≥rio seja muito extenso pode ser invi√°vel colocar um bot√£o para cada aba em todas as p√°ginas.\nJaqueline Medeiros - Todos os direitos reservados\nNeste caso pode ser interessante considerar ter uma p√°gina inicial que leva a todas as p√°ginas do relat√≥rio e colocar um bot√£o de home ou voltar nas outras p√°ginas.\nComo Melhorar a Interface dos Dashboards? Programas de Prototipagem Usar um programa espec√≠fico para fazer o prot√≥tipo do seu painel permite uma liberdade art√≠stica maior comparado ao que os aplicativos de Business Intelligence normalmente fornecem. O Figma √© √≥timo para isso, voc√™ pode criar backgrounds e prot√≥tipos avan√ßados com √≥tima qualidade para usar em seus pain√©is de BI.\nVeja um exemplo de um painel que eu fiz a alguns meses atr√°s:\nPainel com os dados\rO plano de fundo desse painel foi feito completamente no Figma, at√© mesmo alguns dos t√≠tulos dos visuais do BI.\nBackground feito no Figma\rVoc√™ pode encontrar mais pain√©is de Power BI que eu fiz para o Alura Challenge: Alura Films, Alura Skimo, and Alura Food.\nFiguras e √çcones Vetor criado por pch.vector - br.freepik.com\nFiguras e √≠cones quando usados corretamente ajudam a destacar o painel, o torna mais chamativo e bonito. H√° diversas formas de se conseguir imagens, caso voc√™ ou sua equipe n√£o consigam criar voc√™s mesmo existe a op√ß√£o de usar plataformas online que disponibilizam imagens vetorizadas. Nessas plataformas existem as op√ß√µes gratuitas, em que exigem algum tipo de atribui√ß√£o, e op√ß√µes premium (pagas), em que muitas vezes n√£o precisa atribuir o autor e possuem uma qualidade maior.\n√çcone de ICONS8\n","permalink":"https://devmedeiros.com/pt/post/2022-04-29-ux-power-bi-dashboards/","summary":"O que √© UX/UI? UX √© a sigla em ingl√™s para Experi√™ncia de Usu√°rio, √© um conceito recente que fala sobre tomar decis√µes de design pensando na experi√™ncia do usu√°rio final. O designer de UX precisa se preocupar se seu produto √© f√°cil de usar e intuitivo, fazendo mudan√ßas nele sempre que necess√°rio para se adequar as necessidades do usu√°rio.\nUI, do ingl√™s, significa Interface do Usu√°rio. √â tudo aquilo que est√° envolvido na intera√ß√£o do usu√°rio e o produto.","title":"UX/UI em Dashboards de Business Intelligence"},{"content":"O que √© o p-valor? Em estat√≠stica temos os testes de hip√≥teses, que s√£o feitos para tomar uma decis√£o, de rejeitar ou n√£o rejeitar a hip√≥tese nula. Alguns exemplos de teste de hip√≥tese s√£o: Neyman-Pearson, Shapiro-Wilk, T de Student, entre outros.\nTodos testes de hip√≥teses possuem uma estat√≠stica de teste espec√≠fico dele. E essa estat√≠stica √© utilizada para avaliar o teste, mas essa tarefa pode ser cansativa at√© com o uso de computadores, pois a maioria dos softwares n√£o devolvem como resposta a estat√≠stica de compara√ß√£o, apenas a estat√≠stica amostral. Nesse caso o p-valor vem para facilitar essa compara√ß√£o, pois ele j√° √© uma representa√ß√£o dessa estat√≠stica de teste. Ele representa a probabilidade de se obter uma estat√≠stica de teste igual ou mais extrema que a calculada na sua amostra, considerando a hip√≥tese nula como verdadeira.\nIsso facilita, pois sabendo o n√≠vel de confian√ßa que voc√™ quer testar a sua hip√≥tese basta comparar se o p-valor √© menor ou maior que o seu n√≠vel de confian√ßa, enquanto que se fosse usar a estat√≠stica de teste ainda seria necess√°rio calcular a estat√≠stica para cada n√≠vel de confian√ßa diferente que voc√™ fosse comparar. Ent√£o suponha que queira comparar 1%, 5% e 10%, voc√™ teria que calcular tr√™s estat√≠sticas de teste diferentes para comparar a sua estat√≠stica amostral.\nComo usar ele? √â muito comum quando estamos aprendendo estat√≠stica por conta pr√≥pria lermos que se o p-valor for menor que 5% rejeitamos a hip√≥tese ou que se for maior \u0026ldquo;aceitamos\u0026rdquo; a hip√≥tese.\nO valor com o qual comparamos o p-valor deve ser definido juntamente com pessoas da √°rea de neg√≥cio do que voc√™ est√° trabalhando, √© muito comum em alguns setores utilizarem um p-valor muito pequeno como 1% ou at√© 0,1% e em outros usarem valores maiores de que 5%.\nVeja que um p-valor de 0,02 seria rejeitado se considerarmos Œ± = 1%, mas n√£o seria se Œ± = 5%. Na d√∫vida sobre qual usar, primeiramente √© recomendado tomar essa decis√£o antes de fazer o teste. Segundo, tenha em mente que um Œ± = 1% vai ter uma confian√ßa de 99% (1-Œ±), enquanto que se fosse 5% seria apenas 95%. Pode parecer que √© melhor pegar o valor que lhe d√° mais \u0026ldquo;confian√ßa\u0026rdquo;, mas um p-valor muito pequeno pode levar a mais rejei√ß√µes da sua hip√≥tese.\nA verdade √© que os testes de hip√≥teses s√≥ nos d√£o a informa√ß√£o da rejei√ß√£o, quando uma hip√≥tese nula n√£o √© rejeitada isso quer dizer que n√£o foram encontradas evid√™ncias que contradizem o que ela afirma, isso n√£o quer dizer que provamos que ela est√° correta. Ent√£o √© preciso tomar muito cuidado ao utilizar o p-valor.\nInterpretando a medida Uma forma de interpretar a medida muito comum √© \u0026ldquo;Rejeita-se a hip√≥tese nula, com Œ±% de confian√ßa\u0026rdquo;, no caso de rejei√ß√£o (em que o p-valor \u0026gt; Œ±) e no caso de n√£o rejei√ß√£o (p-valor \u0026lt; Œ±) \u0026ldquo;N√£o foram encontradas evid√™ncias suficientes para rejeitar a hip√≥tese nula, com Œ±% de confian√ßa\u0026rdquo;.\n","permalink":"https://devmedeiros.com/pt/post/2022-04-12-comprehending-the-p-value/","summary":"O que √© o p-valor? Em estat√≠stica temos os testes de hip√≥teses, que s√£o feitos para tomar uma decis√£o, de rejeitar ou n√£o rejeitar a hip√≥tese nula. Alguns exemplos de teste de hip√≥tese s√£o: Neyman-Pearson, Shapiro-Wilk, T de Student, entre outros.\nTodos testes de hip√≥teses possuem uma estat√≠stica de teste espec√≠fico dele. E essa estat√≠stica √© utilizada para avaliar o teste, mas essa tarefa pode ser cansativa at√© com o uso de computadores, pois a maioria dos softwares n√£o devolvem como resposta a estat√≠stica de compara√ß√£o, apenas a estat√≠stica amostral.","title":"Compreendendo o P-Valor"},{"content":"Tools used: Power BI, Figma, SQL\nCategory: Dashboard\nEste dashboard √© o √∫ltimo de tr√™s do segundo desafio Alura Challenge BI.\nA Alura Skimo est√° interessada em analisar seus dados de vendas, para ajudar com isso eu fiz este dashboard. Ele √© composto de tr√™s p√°ginas. A primeira apresenta um resumo com todas as principais medidas que encontramos no painel, filtrado para mostrar o m√™s mais recente. Nesta primeira p√°gina, voc√™ pode parar o cursor do mouse sobre uma medida e isso far√° com que apare√ßa um pequeno gr√°fico com a s√©rie hist√≥rica com uma linha de tend√™ncia.\nSeguindo para a pr√≥xima p√°gina, nela voc√™ pode ver toda a informa√ß√£o sobre os produtos vendidos pela Alura Skimo. Voc√™ pode filtrar os dados por sabor de sorvete, tipo de embalagem, categoria, e custo do produto. Ela mostra a informa√ß√£o b√°sica sobre os produtos, junto de um ranque dos produtos que s√£o os mais bem vendidos e dois gr√°ficos que mostram as vendas por sabor e vendas por categoria.\nNa √∫ltima p√°gina, voc√™ pode encontrar informa√ß√µes sobre os vendedores da nossa empresa. Ele mostra quando o funcion√°rio entrou para a empresa, a comiss√£o deles, o faturamento e quantas vendas cada um fez, tudo isso no √∫ltimo ano (2018).\nEsse painel foi complexo comparado aos outros dois, pois nosso banco de dados veio de arquivos SQL. Primeiro eu tive que criar o banco de dados e carregar cada arquivo SQL para ele, ent√£o eu s√≥ tive que carregar o banco para o Power BI. Por fim, toda a limpeza, tratamento e processamento de dados foi feito no pr√≥prio Power BI.\nCaso voc√™ queira olhar os c√≥digos e arquivos utilizados neste projeto, voc√™ pode acessar meu reposit√≥rio do github.\n","permalink":"https://devmedeiros.com/pt/post/2022-03-08-alura-skimo-powerbi/","summary":"Tools used: Power BI, Figma, SQL\nCategory: Dashboard\nEste dashboard √© o √∫ltimo de tr√™s do segundo desafio Alura Challenge BI.\nA Alura Skimo est√° interessada em analisar seus dados de vendas, para ajudar com isso eu fiz este dashboard. Ele √© composto de tr√™s p√°ginas. A primeira apresenta um resumo com todas as principais medidas que encontramos no painel, filtrado para mostrar o m√™s mais recente. Nesta primeira p√°gina, voc√™ pode parar o cursor do mouse sobre uma medida e isso far√° com que apare√ßa um pequeno gr√°fico com a s√©rie hist√≥rica com uma linha de tend√™ncia.","title":"Alura Skimo - Power BI Dashboard"},{"content":"Tools used: Power BI, Google Sheets, Figma\nCategory: Dashboard\nEsse painel √© o segundo de tr√™s que estou fazendo para o segundo desafio Alura Challenge BI.\nA Alura Food est√° interessada em expandir seus neg√≥cios para o mercado indiano. Para isso, a empresa pediu para calcular medidas que os ajudem a tomarem uma melhor decis√£o.\nPrimeiramente, eu fiz uma jun√ß√£o dos bancos de dados e limpei eles atrav√©s do Power BI, traduzi alguns dos textos de ingl√™s para portugu√™s atrav√©s da Planilhas Google, e converti o pre√ßo das refei√ß√µes da sua moeda original para o real (moeda brasileira). Por fim, eu usei o Figma para fazer o background, incluindo imagens e t√≠tulos.\nNeste projeto, eu optei por usar apenas uma p√°gina para mostrar toda a informa√ß√£o pedida, pois eu acredito que isso facilita a an√°lise dos dados.\nA maioria dos restaurantes neste mercado indiano n√£o oferecem entrega online, com apenas 19,21% deles tendo este servi√ßo. A avalia√ß√£o m√©dia dos restaurantes √© de 3,72, de um total de 5, essa avalia√ß√£o tamb√©m √© apresentada em formato textual, com um Muito Bom sendo uma nota acima de 4.\nO pre√ßo m√©dio de uma refei√ß√£o por pessoa √© de R$ 39,48 (em torno de USD 7,65). E h√° 9577 restaurantes diferentes em todo o banco de dados, dos quais 3968, especializam na culin√°ria do norte indiano. Nova Delhi √©, de longe, o local mais popular para se abrir um restaurante, com 5473 deles, a segunda cidade √© Gurgaon, com 1118 restaurantes.\nCaso voc√™ queira olhar os c√≥digos e arquivos utilizados neste projeto, voc√™ pode acessar meu reposit√≥rio do github.\n","permalink":"https://devmedeiros.com/pt/post/2022-02-26-alura-food-powerbi/","summary":"Tools used: Power BI, Google Sheets, Figma\nCategory: Dashboard\nEsse painel √© o segundo de tr√™s que estou fazendo para o segundo desafio Alura Challenge BI.\nA Alura Food est√° interessada em expandir seus neg√≥cios para o mercado indiano. Para isso, a empresa pediu para calcular medidas que os ajudem a tomarem uma melhor decis√£o.\nPrimeiramente, eu fiz uma jun√ß√£o dos bancos de dados e limpei eles atrav√©s do Power BI, traduzi alguns dos textos de ingl√™s para portugu√™s atrav√©s da Planilhas Google, e converti o pre√ßo das refei√ß√µes da sua moeda original para o real (moeda brasileira).","title":"Alura Food - Power BI Dashboard"},{"content":"Ferramentas utilizadas: Power BI, Planilhas Google, Figma\nCategoria: Dashboard\nEste painel √© o primeiro de tr√™s que eu estarei fazendo nas pr√≥ximas semanas como parte do segundo desafio Alura Challenge BI.\nO objetivo deste painel √© ajudar a encontrar a melhor sele√ß√£o para um filme que ser√° produzido.\nCom isso em mente, eu explorei na primeira aba um pequeno resumo sobre os filmes no banco de dados, com ela voc√™ pode ter uma ideia geral dos nossos dados. Na segunda aba √© apresentado a nota no IMDB e o Meta Score dos filmes. Eu tamb√©m criei uma medida que mostra o quanto essas duas avalia√ß√µes concordam entre si. Uma medida de 100 quer dizer que n√£o concordam nem um pouco e 0 quer dizer concordam completamente, a medida de concord√¢ncia foi de 9,48.\nNossa terceira aba apresenta informa√ß√£o sobre as estrelas dos filmes, os 10 atores com a maior rentabilidade, e os 10 atores com a maior contagem de filmes.\nA quarta aba apresenta a distribui√ß√£o da renda bruta pela quantidade de g√™neros diferentes que um filme tem. Ela tamb√©m mostra quantos filmes tem um certo g√™nero, como por exemplo, Drama √© a escolha mais popular para g√™nero de filme, com 72% dos filmes do banco de dados. Por fim, essa aba tamb√©m mostra a renda bruta m√©dia por g√™nero.\nA quinta e √∫ltima aba mostra um pouco de informa√ß√£o sobre a classifica√ß√£o indicativa brasileira e mostra o Meta Score m√©dio para filmes com certifica√ß√£o. Ela tamb√©m mostra a renda bruta, em m√©dia, para cada classifica√ß√£o indicativa.\n","permalink":"https://devmedeiros.com/pt/post/2022-02-17-alura-films-powerbi/","summary":"Ferramentas utilizadas: Power BI, Planilhas Google, Figma\nCategoria: Dashboard\nEste painel √© o primeiro de tr√™s que eu estarei fazendo nas pr√≥ximas semanas como parte do segundo desafio Alura Challenge BI.\nO objetivo deste painel √© ajudar a encontrar a melhor sele√ß√£o para um filme que ser√° produzido.\nCom isso em mente, eu explorei na primeira aba um pequeno resumo sobre os filmes no banco de dados, com ela voc√™ pode ter uma ideia geral dos nossos dados.","title":"Alura Films - Power BI Dashboard"},{"content":"\rO show, apresentado por Tyler Renelle da Depth, oferece uma lista com recursos na qual voc√™ pode encontrar todos os livros, cursos, e sites mencionados durante o podcast. √â um √≥timo podcast para quem est√° aprendendo sobre aprendizado de m√°quina, podendo ser √∫til para iniciantes, entusiastas, ou para algu√©m que est√° procurando se aprofundar ainda mais no t√≥pico. Desde 2021 o show est√° sendo renovado para atualizar o conte√∫do.\nO show come√ßa falando sobre o que √© ci√™ncia de dados e como ela se relaciona com aprendizado de m√°quina e intelig√™ncia artificial. Ele tamb√©m fala sobre as primeiras tentativas em criar IA, com alguns exemplos vindos desde o s√©culo 13.\nEu gosto que o show fala sobre conceitos de aprendizado de m√°quina de uma forma diferente da qual eu estou acostumada. Quando pessoas falam sobre aprendizado de m√°quina, eu, como Estat√≠stica, sempre senti que entendia sobre o que as pessoas estavam falando, exceto que eu n√£o conhecia algumas palavras chaves que elas usavam. Por exemplo, o que engenheiros de aprendizado de m√°quina chamam de features eu aprendi como vari√°vel, ent√£o eu ficava confusa quando conversava com amigos sobre aprendizado de m√°quina quando eles tinham um antecedente diferente do meu (ci√™ncia da computa√ß√£o, por exemplo). Esse √© um dos motivos que faz eu gostar tanto do podcast, ele fala em ricos detalhes sobre cada conceito de aprendizado de m√°quina, ent√£o se ele fala sobre algo que eu conhe√ßo por outro nome eu consigo fazer a conex√£o.\n","permalink":"https://devmedeiros.com/pt/post/2022-01-24-podcast-review-mlg/","summary":"O show, apresentado por Tyler Renelle da Depth, oferece uma lista com recursos na qual voc√™ pode encontrar todos os livros, cursos, e sites mencionados durante o podcast. √â um √≥timo podcast para quem est√° aprendendo sobre aprendizado de m√°quina, podendo ser √∫til para iniciantes, entusiastas, ou para algu√©m que est√° procurando se aprofundar ainda mais no t√≥pico. Desde 2021 o show est√° sendo renovado para atualizar o conte√∫do.","title":"Review do Podcast - Machine Learning Guide"},{"content":"Recentemente eu terminei um curso na Alura chamado Python para Data Science e eu quero colocar o que eu aprendi em pr√°tica, para isso eu vou fazer uma an√°lise descritiva nesse banco de dados Amazon Top 50 Bestselling Books 2009 - 2019. Nele h√° 550 livros e eles foram categorizados como fiction (fic√ß√£o) e non-fiction (n√£o fic√ß√£o) pelo Goodreads. Todo o c√≥digo pode ser visto aqui.\nEu comecei olhando as cinco primeiras observa√ß√µes do banco de dados.\nName Author User Rating Reviews Price Year Genre 10-Day Green Smoothie Cleanse JJ Smith 4.7 17350 8 2016 Non Fiction 11/22/63: A Novel Stephen King 4.6 2052 22 2011 Fiction 12 Rules for Life: An Antidote to Chaos Jordan B. Peterson 4.7 18979 15 2018 Non Fiction 1984 (Signet Classics) George Orwell 4.7 21424 6 2017 Fiction 5,000 Awesome Facts (About Everything!) (Natio\u0026hellip; National Geographic Kids 4.8 7665 12 2019 Non Fiction Aqui √© poss√≠vel ver que os dados tem o Year (ano) em que o livro estava no top 50 de mais vendidos, seu Price (pre√ßo), a m√©dia dos User Rating (avalia√ß√£o dos usu√°rios), total de Reviews (avalia√ß√µes), Author (autor), Name (nome do livro) e por fim, Genre (g√™nero).\nN√£o h√° valores nulos no banco de dados. E dos 550 livros h√° 248 autores diferentes, ent√£o vamos ver quais autores possuem mais livros no top 50 dos mais vendidos neste per√≠odo.\nAutor N√∫mero de livros Jeff Kinney 12 Gary Chapman 11 Rick Riordan 11 Suzanne Collins 11 American Psychological Association 10 Dr. Seuss 9 Gallup 9 Rob Elliott 8 Stephen R. Covey 7 Stephenie Meyer 7 Dav Pilkey 7 Bill O\u0026rsquo;Reilly 7 Eric Carle 7 O autor com mais livros no top 50 foi Jeff Kinney, empatado em segundo, com 11 livros, foi Gary Chapman, Rick Riordan, e Suzanne Collins. Empatado em 9¬∫, est√° Stephen R. Covey, Stephenie Meyer, Dav Pilkey, Bill O\u0026rsquo;Reilly, e Eric Carle, com 7 livros cada.\nCom o gr√°fico de violino podemos ver como est√° concentrado a avalia√ß√£o dos usu√°rios e como os dados s√£o compostos de livros bestsellers faz sentido que a avalia√ß√£o dos usu√°rios est√° em sua maioria concentrada em torno de 4.5 e 4.75.\nEsse boxplot da quantidade de avalia√ß√µes por ano mostra que a variabilidade aumentou atrav√©s dos anos, tendo o seu pico em 2014 e gradualmente estabilizando. Podemos ver tamb√©m que nos primeiros anos, 2010 e 2011, havia mais outliers nos dados.\nG√™nero Avalia√ß√£o do Usu√°rio Pre√ßo Fic√ß√£o 4.65 10.85 N√£o Fic√ß√£o 4.60 14.84 A avalia√ß√£o m√©dia do usu√°rio por g√™nero parece ser semelhante, com apenas 0.05 de diferen√ßa, mas o pre√ßo j√° apresenta uma diferen√ßa maior, 10.85 para fic√ß√£o e 14.84 para n√£o fic√ß√£o. Para termos certezas de que essas diferen√ßas s√£o estatisticamente significantes, eu vou utilizar o teste de Mann-Whitney.\nA hip√≥tese nula do teste de Mann-Whitney √© de que as amostras possuem a mesma distribui√ß√£o, e em ambos os casos, n√≥s rejeitamos a hip√≥tese nula com 95% de confian√ßa. O p-valor para os dados do pre√ßo foi de 8.34e-08 e o p-valor para a avalia√ß√£o do usu√°rio foi de 1.495e-07.\nPara mostrar visualmente qu√£o diferente as suas distribui√ß√£o s√£o, podemos olhar para os seguintes gr√°ficos.\nA distribui√ß√£o para os pre√ßos de livros de fic√ß√£o √© fortemente inclinados para a esquerda e consistentemente diminuem a medida que o pre√ßo aumenta. Enquanto que os livros de fic√ß√£o come√ßam altos e se tornam ainda mais altos, com 120 e quase 140 ocorr√™ncias nas duas primeiras categorias, ent√£o ele rapidamente diminui.\nA distribui√ß√£o para a avalia√ß√£o do usu√°rio do g√™nero de fic√ß√£o lentamente aumenta, tendo seu pico pr√≥ximo de 4.8. E a distribui√ß√£o para o g√™nero de n√£o fic√ß√£o tem seu pico logo ap√≥s 4.6.\n","permalink":"https://devmedeiros.com/pt/post/2021-12-28-amazon-top-50-books/","summary":"Recentemente eu terminei um curso na Alura chamado Python para Data Science e eu quero colocar o que eu aprendi em pr√°tica, para isso eu vou fazer uma an√°lise descritiva nesse banco de dados Amazon Top 50 Bestselling Books 2009 - 2019. Nele h√° 550 livros e eles foram categorizados como fiction (fic√ß√£o) e non-fiction (n√£o fic√ß√£o) pelo Goodreads. Todo o c√≥digo pode ser visto aqui.\nEu comecei olhando as cinco primeiras observa√ß√µes do banco de dados.","title":"An√°lise Descritiva do Top 50 Livros Bestsellers da Amazon 2009 - 2019"},{"content":"Introdu√ß√£o Eu estou aprendendo visualiza√ß√£o de dados no Python e eu me vejo como algu√©m que aprende fazendo, por isso eu vou fazer alguns gr√°ficos simples usando o pacote seaborn que poder√£o ser utilizados como refer√™ncia sempre que precisar refrescar a mem√≥ria.\nPrimeiramente √© necess√°rios que os pacotes estejam propriamente importados, ap√≥s isso eu carrego o banco de dados iris.\nimport pandas as pd import seaborn as sns import matplotlib.pyplot as plt url = \u0026#34;https://git.io/JXciW\u0026#34; iris = pd.read_csv(url) Caso n√£o esteja familiarizado com o banco de dados iris, veja as cinco primeiras linhas dele a seguir:\nsepal_length sepal_width petal_length petal_width species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa Gr√°fico de barras Criar um simples gr√°fico de barras.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris) Fazendo um gr√°fico de barras horizontais.\nsns.barplot(x=\u0026#34;petal_width\u0026#34;, y=\u0026#34;species\u0026#34;, data=iris) Ordem das barras personalizada.\nsns.barplot( x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, order=[\u0026#34;virginica\u0026#34;, \u0026#34;setosa\u0026#34;, \u0026#34;versicolor\u0026#34;]) Acrescentar limites para as barras de erro.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, capsize=.2) Gr√°fico de barra sem barras de erro.\nsns.barplot(x=\u0026#34;species\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, ci=None) Gr√°fico de dispers√£o Um gr√°fico de dispers√£o simples.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris) Acrescentando grupos no gr√°fico de dispers√£o.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, hue=\u0026#34;species\u0026#34;) Acrescentando grupos e escalando os pontos de um gr√°fico de dispers√£o.\nsns.scatterplot( x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, hue=\u0026#34;sepal_length\u0026#34;, size=\u0026#34;sepal_length\u0026#34;) Legenda e Eixos Para mover a legenda do gr√°fico para fora da √°rea de plotagem, voc√™ pode utilizar bbox_to_anchor = (1,1), loc=2. O gr√°fico a seguir possui um titulo personalizado, um novo t√≠tulo para o eixo x e pro eixo y.\nsns.scatterplot(x=\u0026#34;sepal_width\u0026#34;, y=\u0026#34;petal_width\u0026#34;, data=iris, hue=\u0026#34;species\u0026#34;) plt.legend( title=\u0026#34;Species\u0026#34;, bbox_to_anchor = (1,1), loc=2) plt.xlabel(\u0026#34;Sepal Width\u0026#34;) plt.ylabel(\u0026#34;Petal Width\u0026#34;) plt.title(\u0026#34;Sepal Width x Petal Width\u0026#34;) ","permalink":"https://devmedeiros.com/pt/post/2021-11-07-seaborn-package-guide/","summary":"Introdu√ß√£o Eu estou aprendendo visualiza√ß√£o de dados no Python e eu me vejo como algu√©m que aprende fazendo, por isso eu vou fazer alguns gr√°ficos simples usando o pacote seaborn que poder√£o ser utilizados como refer√™ncia sempre que precisar refrescar a mem√≥ria.\nPrimeiramente √© necess√°rios que os pacotes estejam propriamente importados, ap√≥s isso eu carrego o banco de dados iris.\nimport pandas as pd import seaborn as sns import matplotlib.pyplot as plt url = \u0026#34;https://git.","title":"Guia do Pacote de Python seaborn"},{"content":"O pacote data.table √© um dos pacotes de manipula√ß√£o de dados mais r√°pido, atualmente ele √© mais r√°pido at√© que o pandas e dplyr 1. A sintaxe de um data.table √© dt[i, j, by], em que:\ni √© utilizado para amostrar linhas j √© utilizado para amostrar colunas by √© utilizado para amostrar grupos, igual ao GROUP BY do SQL Voc√™ pode ler em voz alta como2:\nPegue dt, amostra/reordene as linhas usando i, ent√£o calcule j, agrupando por by.\nUm data.table tamb√©m √© um data.frame e todas as manipula√ß√µes de dados b√°sicas que voc√™ pode usar em um data.frame se aplica a um data.table. Como ncol(), nrow(), names(), summary(). Mas ele n√£o para por a√≠, por exemplo data.table possui uma vari√°vel especial .N que √© um integral que contains os n√∫meros das linhas no grupo. Se voc√™ usar dt[.N] voc√™ ver√° a √∫ltima linha do seu data.table.\nOutra coisa interessante do data.table √© que se voc√™ quiser filtrar/amostrar uma coluna, voc√™ n√£o precisa utilizar df$x[df$x == 1] voc√™ pode simplesmente usar dt[x == 1] o que torna o seu c√≥digo mais limpo e f√°cil de ler.\nVoc√™ tamb√©m tem a possibilidade de utilizar operadores especiais como: %like%, %in% e %between%. Estes operadores funcionam como operadores de SQL, LIKE, IN, e BETWEEN, respectivamente.\nSe voc√™ est√° familiarizado com SQL tem uma coisa que esse pacote oferece que ir√° chamar a sua aten√ß√£o. No ingl√™s se chama chaining (acorrentar), que permite a voc√™ a fazer uma sequ√™ncia de opera√ß√µes em um data.table, voc√™ apenas precisa utilizar dt[][] e acorrentar m√∫ltiplas opera√ß√µes com \u0026ldquo;[]\u0026rdquo;.\nMas este n√£o s√£o todos os operadores, com := voc√™ pode alterar dados sem fazer uma nova c√≥pia na mem√≥ria.\nCaso queira come√ßar a usar o pacote eu sugiro que use a cheatsheet (folha de refer√™ncia/colinha). √â extramente √∫til caso j√° tenha um conhecimento b√°sico sobre data.frames.\nhttps://h2oai.github.io/db-benchmark/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://devmedeiros.com/pt/post/2021-10-27-data-table/","summary":"O pacote data.table √© um dos pacotes de manipula√ß√£o de dados mais r√°pido, atualmente ele √© mais r√°pido at√© que o pandas e dplyr 1. A sintaxe de um data.table √© dt[i, j, by], em que:\ni √© utilizado para amostrar linhas j √© utilizado para amostrar colunas by √© utilizado para amostrar grupos, igual ao GROUP BY do SQL Voc√™ pode ler em voz alta como2:\nPegue dt, amostra/reordene as linhas usando i, ent√£o calcule j, agrupando por by.","title":"Uma Vis√£o Geral Sobre o Pacote data.table do R"},{"content":"Ferramentas utilizadas: R, ggplot, Shiny\nCategoria: Simula√ß√£o\nO meu objetivo com este projeto √© de simular o ambiente de um jogo de 21, tamb√©m conhecido como blackjack. Assim, eu decidi fazer diversas fun√ß√µes para emular o comportamento do dealer, de um jogador iniciante, um jogador cauteloso e um estrategista. Com esse conjunto de fun√ß√µes voc√™ pode rodar um jogo com p jogadores, d baralhos e quaisquer combina√ß√µes de arqu√©tipos de jogadores. Al√©m disso, tamb√©m pode rodar o jogo n vezes.\nEu tamb√©m fiz uma aplica√ß√£o shiny para demonstrar como a simula√ß√£o funciona. No aplicativo, voc√™ √© limitado no n√∫mero de jogadores, mas caso queira rodar o c√≥digo com mais jogadores eu sugiro que olhe o resposit√≥rio do GitHub. Nele voc√™ encontra as regras consideradas para a simula√ß√£o e o c√≥digo completo.\nCaso seja familiar com a linguagem de programa√ß√£o R, voc√™ tamb√©m pode rodar o aplicativo localmente, basta carregar a biblioteca do shiny library(shiny) e rodar o c√≥digo runGitHub(\u0026quot;blackjack-simulation\u0026quot;, \u0026quot;devmedeiros\u0026quot;, ref = \u0026quot;main\u0026quot;).\nO app √© composto de uma barra lateral com um espa√ßo para escolher os arqu√©tipos, o n√∫mero de baralhos a ser usados e quantas rodadas voc√™ quer simular. Dependendo de quantas rodadas voc√™ escolher a simula√ß√£o pode ficar mais lenta, pois a simula√ß√£o roda de acordo com as suas escolhas todas vez que clica no bot√£o RUN SIMULATION RUN.\nNa aba plot, nota-se a evolu√ß√£o da taxa de perda atrav√©s das rodadas.\n1 quer dizer que o jogador perdeu aquela rodada e um 0 quer dizer que ele ganhou.\nA aba game setup mostra todas as cartas distribu√≠das na simula√ß√£o, cada carta foi entregue da esquerda para a direita e uma c√©lula em branco quer dizer que o jogador n√£o pediu pra receber outra carta (hit, bate).\nPor fim, a aba lose rate mostra os mesmo dados da aba plot, mas em formato de tabela. Isso √© √∫til quando se quer analisar como uma estrat√©gia foi melhor do que outra.\n","permalink":"https://devmedeiros.com/pt/post/2021-10-24-blackjack-simulation/","summary":"\u003cp\u003e\u003cstrong\u003eFerramentas utilizadas:\u003c/strong\u003e R, ggplot, Shiny\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCategoria:\u003c/strong\u003e Simula√ß√£o\u003c/p\u003e\n\u003chr\u003e","title":"Simula√ß√£o de 21"},{"content":"Eu quero fazer uma an√°lise de sentimentos usando o R como uma forma de aprender. Com isso em mente come√ßamos carregando todos os pacotes que iremos utilizar.\nlibrary(readr) library(dplyr) library(tidytext) library(tokenizers) library(stopwords) library(ggplot2) Ent√£o precisamos carregar nosso banco de dados. Esses dados s√£o do Kaggle Fake and real news dataset.\nFake \u0026lt;- read_csv(\u0026#39;~/fakenews/Fake.csv\u0026#39;) True \u0026lt;- read.csv(\u0026#39;~/fakenews/True.csv\u0026#39;) Eu quero unir ambos os dados, mas antes √© preciso criar uma nova columa que ir√° informar de onde os dados vieram.\nFake$news \u0026lt;- \u0026#39;fake\u0026#39; True$news \u0026lt;- \u0026#39;real\u0026#39; data \u0026lt;- rbind(Fake,True) Agora podemos iniciar a limpeza dos dados. Neste primeiro momento, fazemos os tokens nas vari√°veis title e text. Em seguida iremos remover as stopwords (palavras redundantes) de acordo com a fonte snowball do pacote stopwords.\ntitle \u0026lt;- tibble(news = data$news, text = data$title) corpus \u0026lt;- tibble(news = data$news, corpus = data$text) tidy_title \u0026lt;- title %\u0026gt;% unnest_tokens(word, text, token = \u0026#39;words\u0026#39;) %\u0026gt;% filter(!(word %in% stopwords(source = \u0026#39;snowball\u0026#39;))) tidy_corpus \u0026lt;- corpus %\u0026gt;% unnest_tokens(word, corpus, token = \u0026#39;words\u0026#39;) %\u0026gt;% filter(!(word %in% stopwords(source = \u0026#34;snowball\u0026#34;))) Com os dados limpos podemos selecionar as dez palavras mais frequentes dos t√≠tulos das noticias, separado por grupo real ou falso.\np0 \u0026lt;- tidy_title %\u0026gt;% group_by(news, word) %\u0026gt;% summarise(n = n()) %\u0026gt;% arrange(desc(n)) %\u0026gt;% slice(1:10) T√≠tulos de not√≠cias falsas mencionam muito mais video e trump, 8477 e 7874, respectivamente. J√° no caso de t√≠tulos de not√≠cias reais, trump tamb√©m √© uma das palavras mais mencionadas, aparecendo em primeiro com 4883 apari√ß√µes, seguido por u.s com 4187 e says com 2981.\nAgora iremos preparar os dados para a an√°lise de sentimento. Eu estou interessada em classificar os dados em sentimentos de alegria, raiva, medo ou surpresa, por exemplo. Ent√£o eu iriei utilizar o os dados de nrc Saif Mohammad and Peter Turney.\np1 \u0026lt;- tidy_title %\u0026gt;% inner_join(get_sentiments(\u0026#39;nrc\u0026#39;)) %\u0026gt;% group_by(sentiment, news) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n/sum(n)) Disgust (nojo) aparenta ser o sentimento mais comum envolvendo t√≠tulos de not√≠cias falsas, enquanto que trust (confian√ßa) √© o menor, mesmo que ainda seja maior que 50%. Em geral, t√≠tulos de not√≠cias falsas aparentam ter mais \u0026ldquo;sentimento\u0026rdquo; do que t√≠tulos de not√≠cias reais, neste banco de dados. Isso vale at√© para sentimentos positivos como joy (alegria) e surprise (surpresa).\np2 \u0026lt;- tidy_corpus %\u0026gt;% inner_join(get_sentiments(\u0026#39;nrc\u0026#39;)) %\u0026gt;% group_by(sentiment, news) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n/sum(n)) Para o corpo das not√≠cias reais pode-se notas que os mesmos sentimentos s√£o prevalentes, mas a propor√ß√£o √© menor comparado ao t√≠tulo. Um artigo de not√≠cias falsas perde confian√ßa (trust) quando o leitor l√™ o corpo do artigo. Ele tamb√©m se torna menos negativo (negative) e apresenta menos medo (fear)\nUma melhoria que poderia ser feito aqui √© tentar construir nosso pr√≥prio dicion√°rio de palavras redundantes (stopwords) e alterar a forma que a toneiza√ß√£o foi feita. Pois houveram momentos em que trump e trump\u0026rsquo;s n√£o corresponderam a mesma coisa e se estes dados tivessem sido usados para treinar um modelo isso poderia se tornar um problema.\n","permalink":"https://devmedeiros.com/pt/post/2021-10-12-fakenews-sentiment/","summary":"Eu quero fazer uma an√°lise de sentimentos usando o R como uma forma de aprender. Com isso em mente come√ßamos carregando todos os pacotes que iremos utilizar.\nlibrary(readr) library(dplyr) library(tidytext) library(tokenizers) library(stopwords) library(ggplot2) Ent√£o precisamos carregar nosso banco de dados. Esses dados s√£o do Kaggle Fake and real news dataset.\nFake \u0026lt;- read_csv(\u0026#39;~/fakenews/Fake.csv\u0026#39;) True \u0026lt;- read.csv(\u0026#39;~/fakenews/True.csv\u0026#39;) Eu quero unir ambos os dados, mas antes √© preciso criar uma nova columa que ir√° informar de onde os dados vieram.","title":"An√°lise de Sentimentos de Not√≠cias Falsas vs Not√≠cias Reais"},{"content":"Oi! üëã Meu nome √© Jaqueline Medeiros e eu sou uma Analista de Dados. Eu sempre gostei de aprender coisas novas e explorar novas possibilidades e este blog √© um canal no qual eu crio e descubro coisas novas relacionadas a Ci√™ncia de Dados.\nEu quero escrever posts que possam ser lidos por pessoas que n√£o possuem um background t√©cnico, mas tamb√©m quero mostrar e falar sobre os aspectos de programa√ß√£o do que estou aprendendo, ent√£o voc√™ ir√° encontrar um pouco de tudo aqui.\nVoc√™ pode me encontrar em:\nLinkedin: medeiros-jaqueline Github: devmedeiros ","permalink":"https://devmedeiros.com/pt/about/","summary":"about","title":"Sobre"}]