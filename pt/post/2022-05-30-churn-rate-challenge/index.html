<!doctype html><html lang=pt dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Data Science Challenge - Churn Rate | Dev_Medeiros</title><meta name=keywords content="storytelling,python,an√°lise de dados,aprendizado de m√°quina,rede neural"><meta name=description content="Alura fez um desafio de quatro semanas &ldquo;Data Science Challenge&rdquo; utilizando um banco desbalanceado da taxa de evas√£o da empresa Alura Voz"><meta name=author content="Jaqueline Souza Medeiros"><link rel=canonical href=https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/><link crossorigin=anonymous href=/assets/css/stylesheet.481d2c214f23fd54f797bad0047ecdfe6eb5ae2f0f9da421b16ad57d95488cdd.css integrity="sha256-SB0sIU8j/VT3l7rQBH7N/m61ri8PnaQhsWrVfZVIjN0=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://devmedeiros.com/post/2022-05-30-churn-rate-challenge/><link rel=alternate hreflang=pt href=https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4W6Y2T4WX"></script>
<script>var dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D4W6Y2T4WX",{anonymize_ip:!0})}</script><meta property="og:title" content="Data Science Challenge - Churn Rate"><meta property="og:description" content="Alura fez um desafio de quatro semanas &ldquo;Data Science Challenge&rdquo; utilizando um banco desbalanceado da taxa de evas√£o da empresa Alura Voz"><meta property="og:type" content="article"><meta property="og:url" content="https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/"><meta property="og:image" content="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/aluravoz.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-30T16:49:00-03:00"><meta property="article:modified_time" content="2022-06-09T18:08:00-03:00"><meta property="og:site_name" content="Dev_Medeiros"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/aluravoz.png"><meta name=twitter:title content="Data Science Challenge - Churn Rate"><meta name=twitter:description content="Alura fez um desafio de quatro semanas &ldquo;Data Science Challenge&rdquo; utilizando um banco desbalanceado da taxa de evas√£o da empresa Alura Voz"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://devmedeiros.com/pt/post/"},{"@type":"ListItem","position":2,"name":"Data Science Challenge - Churn Rate","item":"https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Data Science Challenge - Churn Rate","name":"Data Science Challenge - Churn Rate","description":"Alura fez um desafio de quatro semanas \u0026ldquo;Data Science Challenge\u0026rdquo; utilizando um banco desbalanceado da taxa de evas√£o da empresa Alura Voz","keywords":["storytelling","python","an√°lise de dados","aprendizado de m√°quina","rede neural"],"articleBody":"Eu fui desafiada a tomar o papel da nova cientista de dados na Alura Voz. Essa empresa fict√≠cia √© do ramo de telecomunica√ß√£o e precisa reduzir sua taxa de evas√£o de clientes.\nEsse desafio √© dividido em quatro semanas. Para a primeira semana o objetivo √© tratar o banco de dados proveniente de uma API. Em seguida, precisamos identificar clientes que s√£o mais propensos a deixar a empresa, usando explora√ß√£o e an√°lise de dados. E ent√£o, na terceira semana, n√≥s usamos modelos de machine learning para prever a taxa de evas√£o da Alura Voz. A √∫ltima semana √© para expor o que fizemos durante o desafio e construir nosso portfolio. Caso esteja interessado em ver o c√≥digo, ele est√° dispon√≠vel no meu reposit√≥rio do GitHub.\nPrimeira Semana Lendo o Banco de Dados O banco de dados foi disponibilizado no formato JSON e num primeiro momento aparenta ser um data frame normal.\nEntretanto, como pode ser observado, customer, phone, internet, e account s√£o suas pr√≥prias tabelas. Ent√£o eu normalizei elas separadamente e depois simplesmente concatenei todas essas tabelas em uma.\nDados Faltantes A primeira vez que eu procurei por dados faltantes nessa base nenhum foi encontrado, mas a medida que eu explorei os dados eu percebi que havia espa√ßos em branco e vazios n√£o sendo contados como NaN. Ent√£o eu corrigi isso e descobri que havia 224 dados faltantes para a vari√°vel Churn e 11 para Charges.Total.\nEu decidi desconsiderar os dados faltantes da vari√°vel Churn, pois este ser√° nosso objeto de estudo e n√£o h√° sentido em estudar algo que n√£o existe. No caso dos dados faltantes de Charges.Total, eu imagino que representa um cliente que n√£o pagou nada ainda, pois todos eles possuem 0 meses de contrato, ou seja, eles acabaram de se tornar clientes, ent√£o eu simplesmente substitui o valor faltante por 0.\nCodifica√ß√£o de Vari√°veis A vari√°vel SeniorCitizen foi a √∫nica que veio com 0 e 1 ao inv√©s de Yes e No. Por hora eu irei trocar esses valores por ‚Äúyes‚Äù e ‚Äúno‚Äù, pois isto torna a an√°lise mais simples de ser lida.\nCharges.Monthly e Charges.Total foram renomeadas para perderem o ponto, pois isto atrapalha na hora de lidar com elas no python.\nSegunda Semana An√°lise de Dados No primeiro gr√°fico podemos ver o qu√£o desbalanceado nosso banco de dados √©. H√° mais de 5000 clientes que n√£o deixaram a empresa e um pouco menos de 2000 que deixaram.\nEu experimentei usar t√©cnicas de sobreamostragem (oversampling) para lidar com esse deslanceamento, mas isto fez com que os modelos de aprendizado de m√°quina tivessem uma performance pior. E subamostragem (undersampling) n√£o √© uma op√ß√£o com um banco de dados desse tamanho, ent√£o eu decidi deixar do jeito que est√°, e quando for hora de separar os dados de treino e teste eu irei estratificar o banco de acordo com a vari√°vel Churn.\nEu tamb√©m gerei 16 gr√°ficos para todas as vari√°veis discretas, para ver todos os gr√°ficos olhe este notebook. O objetivo √© ver se havia algum comportamento que fazia alguns cliente mais propensos a deixar a empresa. √â claro que todas, exceto por gender, parecem ter algum papel em determinar se um cliente vai ou n√£o deixar a empresa. Mais especificamente forma de pagamento, contratos, backup online, suporte t√©cnico, e servi√ßo de internet.\nNo gr√°fico de tenure, eu decidi fazer gr√°ficos de distribui√ß√£o dos meses de contrato do cliente, um gr√°fico para os cliente que n√£o evadiram e um para os que evadiram. Podemos ver que clientes que evadiram o fizeram no in√≠cio do seu tempo na empresa.\nA cobran√ßa mensal m√©dia para os cliente que n√£o evadiram √© de 61,27 unidades monet√°ria, enquanto que clientes que evadiram pagam 74,44. Isso provavelmente √© por conta do tipo de contrato que esses tipo de clintes preferem, mas de qualquer forma √© senso comum que pre√ßos altos afastam clientes.\nO Perfil de Evas√£o Considerando tudo que eu pude observar atrav√©s de gr√°ficos e medidas, eu fiz um perfil de clientes que s√£o mais propensos a evadir a empresa.\nClientes novos s√£o mais propensos a evadir do que clientes antigos.\nClientes com poucos servi√ßos e produtos tendem a deixar a empresa. Se eles n√£o est√£o presos a um contrato mais longo eles aparentam ser mais propensos a abandonar a empresa.\nSobre os meios de pagamentos, cliente que evadem possuem uma prefer√™ncia forte por cheques eletr√¥nicos e usualmente gastam 13,17 unidades monet√°rias a mais que a m√©dia de clientes que n√£o deixaram a empresa.\nTerceira Semana Preparando o Banco de Dados Damos in√≠cio fazendo vari√°veis dummies, de forma que teremos n-1 dummies para n vari√°veis. Ent√£o fazemos uma matriz de correla√ß√£o para avaliar a correla√ß√£o das nossas vari√°veis.\nPodemos ver que a vari√°vel InternetService_No possui correla√ß√µes altas com diversas outras vari√°veis, isso se d√° porque as outras vari√°veis depende do cliente ter ou n√£o acesso a internet. Ent√£o irei tirar essas vari√°veis dependentes do modelo. A mesma coisa ocorre com PhoneService_Yes.\ntenure e ChargesTotal tamb√©m possuem uma alta correla√ß√£o, mas eu testei rodar os modelos sem uma das duas ou ambas e os modelos tiveram uma performance pior e levaram mais tempo para covergirem, ent√£o eu decidi manter elas no modelo, e elas s√£o relevantes para o problema.\nAp√≥s retirar essas vari√°veis eu termino de preparar o banco de dados com uma normaliza√ß√£o das vari√°veis num√©ricas, ChargesTotal e tenure.\nBanco de Dados de Teste e Treino Eu dividi o banco de dados em treino e teste, 20% para teste e o resto para treino. Eu estratifiquei os dados de acordo com a vari√°vel Churn e embaralhei os dados antes de separar. A mesma divis√£o de dados √© usada em todos os modelos. Ap√≥s separar os dados eu decidi fazer uma sobreamostragem (oversampling) dos dados de teste usando SMOTE1, pois os dados s√£o muito desbalanceados. O motivo de eu usar essa t√©cnica apenas nos dados de teste √© que eu n√£o quero ter um resultado viesado, se eu sobreamostrar todo o banco de dados isso quer dizer que eu vou testar meu modelo no mesmo dado que eu o treinei, e este n√£o √© meu objetivo.\nAvalia√ß√£o dos Modelos Eu vou utilizar um classificador dummy para ter uma base para a medida de acur√°cia, e eu tamb√©m vou utilizar as m√©tricas: precision (precis√£o), recall (recorda√ß√£o) and f1 score (medida f1)2. Apesar de que o modelo dummy n√£o ter valor para essas m√©tricas eu vou manter ele para comparar a melhora dos modelos.\nModelo Base O modelo base foi feito atrav√©s de um classificador dummy, basicamente ele diz que todos os clientes se comportam da mesma forma. Neste caso o modelo chutou que nenhum cliente iria deixar a empresa. Usando essa abordagem o modelo base obteve uma acur√°cia de 0,73456.\nA seguir todos os modelos ter√£o a mesma semente aleat√≥ria (random state).\nModelo 1 - Florestas Aleat√≥rias Eu inicio usando uma busca no grid com valida√ß√£o cruzada (grid search with cross-validation) para encontrar os melhores par√¢metros dentro de uma sele√ß√£o de op√ß√µes utilizando o recall como estrat√©gia para avaliar a performance. O melhor modelo encontrado pela busca foi:\nRandomForestClassifier(criterion='entropy', max_depth=5, max_leaf_nodes=70, random_state=22) Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,72534 Medida Precision: 0,48922 Medida Recall: 0,78877 Medida F1: 0,60389 Modelo 2 - Classifica√ß√£o de Vetores de Suporte Linear Neste modelo eu usei os par√¢metros padr√µes e aumentei o teto para o m√°ximo de itera√ß√µes para 900000.\nLinearSVC(max_iter=900000, random_state=22) Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,71966 Medida Precision: 0,48217 Medida Recall: 0,75936 Medida F1: 0,58982 Modelo 3 - Rede Neural Multicamada Perceptron Aqui eu fixei o solucionador LBFGS, pois de acordo com a documenta√ß√£o do scikit-learn ele tem uma performance melhor em banco de dados pequenos 3, e tamb√©m fiz uma busca no grid com valida√ß√£o cruzada para encontrar o melhor tamanho da camada oculta. O melhor modelo foi:\nMLPClassifier(hidden_layer_sizes=(1,), max_iter=9999, random_state=22, solver='lbfgs') Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:\nMedida Accuracy: 0,72818 Medida Precision: 0,49133 Medida Recall: 0,68182 Medida F1: 0,57111 Conclus√£o Ap√≥s rodar os tr√™s modelos, todos usando o mesmo random_state. Eu encontrei as seguintes medidas de acur√°cia e melhorias no desempenho (comparado com o modelo base):\nNo fim, a Floresta Aleat√≥ria teve as melhores m√©tricas. Este modelo consegue recordar uma grande parte dos clientes que evadem corretamente, ainda n√£o √© perfeito, mas j√° √© um ponto de partida. A medida de acur√°cia n√£o √© t√£o alta como eu gostaria, mas para este problema em particular o objetivo √© impedir os clientes de deixar a empresa e √© melhor utilizar recursos para manter um cliente que n√£o vai deixar a empresa do que n√£o fazer nada.\nNo fim, eu gostei desse desafio, pois √© raro eu praticar aprendizado de m√°quina, mas gra√ßas ao desafio eu tive a oportunidade de fazer um pequeno projeto nessa √°rea que √© t√£o importante e relevante. Essa foi a minha primeira vez trabalhando com redes neurais e ajuste de hiperpar√¢metros, e tenho certeza que na pr√≥xima vez terei resultados ainda melhores.\nimbalanced-learn documentation¬†‚Ü©Ô∏é\nAccuracy, Precision, Recall or F1? - Koo Ping Shung¬†‚Ü©Ô∏é\nscikit-learn documentation¬†‚Ü©Ô∏é\n","wordCount":"1509","inLanguage":"pt","image":"https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/aluravoz.png","datePublished":"2022-05-30T16:49:00-03:00","dateModified":"2022-06-09T18:08:00-03:00","author":{"@type":"Person","name":"Jaqueline Souza Medeiros"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://devmedeiros.com/pt/post/2022-05-30-churn-rate-challenge/"},"publisher":{"@type":"Organization","name":"Dev_Medeiros","logo":{"@type":"ImageObject","url":"https://devmedeiros.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://devmedeiros.com/pt/ accesskey=h title="Dev_Medeiros (Alt + H)">Dev_Medeiros</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://devmedeiros.com/ title=English aria-label=üá∫üá∏>üá∫üá∏</a></li></ul></div></div><ul id=menu><li><a href=https://devmedeiros.com/pt/about/ title=sobre><span>sobre</span></a></li><li><a href=https://devmedeiros.com/pt/post/ title=blog><span>blog</span></a></li><li><a href=https://devmedeiros.com/pt/archives/ title=arquivos><span>arquivos</span></a></li><li><a href=https://devmedeiros.com/pt/projects/ title=projetos><span>projetos</span></a></li><li><a href=https://devmedeiros.com/pt/search/ title="pesquisar (Alt + /)" accesskey=/><span>pesquisar</span></a></li></ul></nav></header><main class=main><script src=https://code.jquery.com/jquery-3.4.1.slim.min.js integrity=sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js integrity=sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js integrity=sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6 crossorigin=anonymous></script><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://devmedeiros.com/pt/>In√≠cio</a>&nbsp;¬ª&nbsp;<a href=https://devmedeiros.com/pt/post/>Posts</a></div><h1 class=post-title>Data Science Challenge - Churn Rate</h1><div class=post-meta><span title='2022-05-30 16:49:00 -0300 -0300'>2022-05-30</span>&nbsp;¬∑&nbsp;<span title='2022-06-09 18:08:00 -0300 -0300'>Updated 2022-06-09</span>&nbsp;¬∑&nbsp;8 minutos&nbsp;¬∑&nbsp;Jaqueline Souza Medeiros&nbsp;|&nbsp;Tradu√ß√µes:<ul class=i18n_list><li><a href=https://devmedeiros.com/post/2022-05-30-churn-rate-challenge/>üá∫üá∏</a></li></ul></div></header><figure class=entry-cover><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/aluravoz.png alt="heart with an A inside and you can read 'Alura Voz telecommunication company'"></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Conte√∫do</span></summary><div class=inner><ul><li><a href=#primeira-semana aria-label="Primeira Semana">Primeira Semana</a><ul><li><a href=#lendo-o-banco-de-dados aria-label="Lendo o Banco de Dados">Lendo o Banco de Dados</a></li><li><a href=#dados-faltantes aria-label="Dados Faltantes">Dados Faltantes</a></li><li><a href=#codifica%c3%a7%c3%a3o-de-vari%c3%a1veis aria-label="Codifica√ß√£o de Vari√°veis">Codifica√ß√£o de Vari√°veis</a></li></ul></li><li><a href=#segunda-semana aria-label="Segunda Semana">Segunda Semana</a><ul><li><a href=#an%c3%a1lise-de-dados aria-label="An√°lise de Dados">An√°lise de Dados</a></li><li><a href=#o-perfil-de-evas%c3%a3o aria-label="O Perfil de Evas√£o">O Perfil de Evas√£o</a></li></ul></li><li><a href=#terceira-semana aria-label="Terceira Semana">Terceira Semana</a><ul><li><a href=#preparando-o-banco-de-dados aria-label="Preparando o Banco de Dados">Preparando o Banco de Dados</a></li><li><a href=#banco-de-dados-de-teste-e-treino aria-label="Banco de Dados de Teste e Treino">Banco de Dados de Teste e Treino</a></li><li><a href=#avalia%c3%a7%c3%a3o-dos-modelos aria-label="Avalia√ß√£o dos Modelos">Avalia√ß√£o dos Modelos</a></li><li><a href=#modelo-base aria-label="Modelo Base">Modelo Base</a></li><li><a href=#modelo-1---florestas-aleat%c3%b3rias aria-label="Modelo 1 - Florestas Aleat√≥rias">Modelo 1 - Florestas Aleat√≥rias</a></li><li><a href=#modelo-2---classifica%c3%a7%c3%a3o-de-vetores-de-suporte-linear aria-label="Modelo 2 - Classifica√ß√£o de Vetores de Suporte Linear">Modelo 2 - Classifica√ß√£o de Vetores de Suporte Linear</a></li><li><a href=#modelo-3---rede-neural-multicamada-perceptron aria-label="Modelo 3 - Rede Neural Multicamada Perceptron">Modelo 3 - Rede Neural Multicamada Perceptron</a></li><li><a href=#conclus%c3%a3o aria-label=Conclus√£o>Conclus√£o</a></li></ul></li></ul></div></details></div><div class=post-content><p>Eu fui desafiada a tomar o papel da nova cientista de dados na Alura Voz. Essa empresa fict√≠cia √© do ramo de telecomunica√ß√£o e precisa reduzir sua taxa de evas√£o de clientes.</p><p>Esse desafio √© dividido em quatro semanas. Para a primeira semana o objetivo √© tratar o banco de dados proveniente de uma API. Em seguida, precisamos identificar clientes que s√£o mais propensos a deixar a empresa, usando explora√ß√£o e an√°lise de dados. E ent√£o, na terceira semana, n√≥s usamos modelos de <em>machine learning</em> para prever a taxa de evas√£o da Alura Voz. A √∫ltima semana √© para expor o que fizemos durante o desafio e construir nosso portfolio. Caso esteja interessado em ver o c√≥digo, ele est√° dispon√≠vel no meu <a href=https://github.com/devmedeiros/Challenge-Data-Science>reposit√≥rio</a> do GitHub.</p><h2 id=primeira-semana>Primeira Semana<a hidden class=anchor aria-hidden=true href=#primeira-semana>#</a></h2><h3 id=lendo-o-banco-de-dados>Lendo o Banco de Dados<a hidden class=anchor aria-hidden=true href=#lendo-o-banco-de-dados>#</a></h3><p>O banco de dados foi disponibilizado no formato JSON e num primeiro momento aparenta ser um <em>data frame</em> normal.</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/1%20-%20Data%20Cleaning/table_head.png#center alt="table head with the first five rows"></p><p>Entretanto, como pode ser observado, <code>customer</code>, <code>phone</code>, <code>internet</code>, e <code>account</code> s√£o suas pr√≥prias tabelas. Ent√£o eu normalizei elas separadamente e depois simplesmente concatenei todas essas tabelas em uma.</p><h3 id=dados-faltantes>Dados Faltantes<a hidden class=anchor aria-hidden=true href=#dados-faltantes>#</a></h3><p>A primeira vez que eu procurei por dados faltantes nessa base nenhum foi encontrado, mas a medida que eu explorei os dados eu percebi que havia espa√ßos em branco e vazios n√£o sendo contados como <code>NaN</code>. Ent√£o eu corrigi isso e descobri que havia 224 dados faltantes para a vari√°vel <code>Churn</code> e 11 para <code>Charges.Total</code>.</p><p>Eu decidi desconsiderar os dados faltantes da vari√°vel <code>Churn</code>, pois este ser√° nosso objeto de estudo e n√£o h√° sentido em estudar algo que n√£o existe. No caso dos dados faltantes de <code>Charges.Total</code>, eu imagino que representa um cliente que n√£o pagou nada ainda, pois todos eles possuem 0 meses de contrato, ou seja, eles acabaram de se tornar clientes, ent√£o eu simplesmente substitui o valor faltante por 0.</p><h3 id=codifica√ß√£o-de-vari√°veis>Codifica√ß√£o de Vari√°veis<a hidden class=anchor aria-hidden=true href=#codifica√ß√£o-de-vari√°veis>#</a></h3><p>A vari√°vel <code>SeniorCitizen</code> foi a √∫nica que veio com <code>0</code> e <code>1</code> ao inv√©s de <code>Yes</code> e <code>No</code>. Por hora eu irei trocar esses valores por &ldquo;yes&rdquo; e &ldquo;no&rdquo;, pois isto torna a an√°lise mais simples de ser lida.</p><p><code>Charges.Monthly</code> e <code>Charges.Total</code> foram renomeadas para perderem o ponto, pois isto atrapalha na hora de lidar com elas no <em>python</em>.</p><h2 id=segunda-semana>Segunda Semana<a hidden class=anchor aria-hidden=true href=#segunda-semana>#</a></h2><h3 id=an√°lise-de-dados>An√°lise de Dados<a hidden class=anchor aria-hidden=true href=#an√°lise-de-dados>#</a></h3><p>No primeiro gr√°fico podemos ver o qu√£o desbalanceado nosso banco de dados √©. H√° mais de 5000 clientes que n√£o deixaram a empresa e um pouco menos de 2000 que deixaram.</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/2%20-%20Data%20Analysis/churn.jpg#center alt="bar plot with two bars, the first one is for &amp;rsquo;no&amp;rsquo; and the second is for &amp;lsquo;yes&amp;rsquo;, the first bar is over 5000 count and the second one is around 2000"></p><p>Eu experimentei usar t√©cnicas de sobreamostragem (<em>oversampling</em>) para lidar com esse deslanceamento, mas isto fez com que os modelos de aprendizado de m√°quina tivessem uma performance pior. E subamostragem (<em>undersampling</em>) n√£o √© uma op√ß√£o com um banco de dados desse tamanho, ent√£o eu decidi deixar do jeito que est√°, e quando for hora de separar os dados de treino e teste eu irei estratificar o banco de acordo com a vari√°vel <code>Churn</code>.</p><p>Eu tamb√©m gerei 16 gr√°ficos para todas as vari√°veis discretas, para ver todos os gr√°ficos olhe este <a href=https://github.com/devmedeiros/Challenge-Data-Science/blob/main/2%20-%20Data%20Analysis/data_analysis.ipynb>notebook</a>. O objetivo √© ver se havia algum comportamento que fazia alguns cliente mais propensos a deixar a empresa. √â claro que todas, exceto por <code>gender</code>, parecem ter algum papel em determinar se um cliente vai ou n√£o deixar a empresa. Mais especificamente forma de pagamento, contratos, <em>backup online</em>, suporte t√©cnico, e servi√ßo de internet.</p><p>No gr√°fico de <code>tenure</code>, eu decidi fazer gr√°ficos de distribui√ß√£o dos meses de contrato do cliente, um gr√°fico para os cliente que n√£o evadiram e um para os que evadiram. Podemos ver que clientes que evadiram o fizeram no in√≠cio do seu tempo na empresa.</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/2%20-%20Data%20Analysis/tenure.jpg#center alt="there are two plots side-by-side, in the first one the title is &amp;lsquo;Churn = No&amp;rsquo; the data is along the tenure axis and is in a U shape. the second plot has the title &amp;lsquo;Churn = Yes&amp;rsquo; and starts high and drops fast along the tenure line"></p><p>A cobran√ßa mensal m√©dia para os cliente que n√£o evadiram √© de 61,27 unidades monet√°ria, enquanto que clientes que evadiram pagam 74,44. Isso provavelmente √© por conta do tipo de contrato que esses tipo de clintes preferem, mas de qualquer forma √© senso comum que pre√ßos altos afastam clientes.</p><h3 id=o-perfil-de-evas√£o>O Perfil de Evas√£o<a hidden class=anchor aria-hidden=true href=#o-perfil-de-evas√£o>#</a></h3><p><img loading=lazy src=https://64.media.tumblr.com/tumblr_lojvnhHFH91qlh1s6o1_400.gifv#center alt="person jumping through the window"></p><p>Considerando tudo que eu pude observar atrav√©s de gr√°ficos e medidas, eu fiz um perfil de clientes que s√£o mais propensos a evadir a empresa.</p><ul><li><p>Clientes novos s√£o mais propensos a evadir do que clientes antigos.</p></li><li><p>Clientes com poucos servi√ßos e produtos tendem a deixar a empresa. Se eles n√£o est√£o presos a um contrato mais longo eles aparentam ser mais propensos a abandonar a empresa.</p></li><li><p>Sobre os meios de pagamentos, cliente que evadem possuem uma prefer√™ncia <strong>forte</strong> por cheques eletr√¥nicos e usualmente gastam 13,17 unidades monet√°rias a mais que a m√©dia de clientes que n√£o deixaram a empresa.</p></li></ul><h2 id=terceira-semana>Terceira Semana<a hidden class=anchor aria-hidden=true href=#terceira-semana>#</a></h2><h3 id=preparando-o-banco-de-dados>Preparando o Banco de Dados<a hidden class=anchor aria-hidden=true href=#preparando-o-banco-de-dados>#</a></h3><p>Damos in√≠cio fazendo vari√°veis <em>dummies</em>, de forma que teremos n-1 <em>dummies</em> para n vari√°veis. Ent√£o fazemos uma matriz de correla√ß√£o para avaliar a correla√ß√£o das nossas vari√°veis.</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/3%20-%20Model%20Selection/corr_matrix.jpg#center alt="correlation matrix with all the features"></p><p>Podemos ver que a vari√°vel <code>InternetService_No</code> possui correla√ß√µes altas com diversas outras vari√°veis, isso se d√° porque as outras vari√°veis depende do cliente ter ou n√£o acesso a internet. Ent√£o irei tirar essas vari√°veis dependentes do modelo. A mesma coisa ocorre com <code>PhoneService_Yes</code>.</p><p><code>tenure</code> e <code>ChargesTotal</code> tamb√©m possuem uma alta correla√ß√£o, mas eu testei rodar os modelos sem uma das duas ou ambas e os modelos tiveram uma performance pior e levaram mais tempo para covergirem, ent√£o eu decidi manter elas no modelo, e elas s√£o relevantes para o problema.</p><p>Ap√≥s retirar essas vari√°veis eu termino de preparar o banco de dados com uma normaliza√ß√£o das vari√°veis num√©ricas, <code>ChargesTotal</code> e <code>tenure</code>.</p><h3 id=banco-de-dados-de-teste-e-treino>Banco de Dados de Teste e Treino<a hidden class=anchor aria-hidden=true href=#banco-de-dados-de-teste-e-treino>#</a></h3><p>Eu dividi o banco de dados em treino e teste, 20% para teste e o resto para treino. Eu estratifiquei os dados de acordo com a vari√°vel <code>Churn</code> e embaralhei os dados antes de separar. A mesma divis√£o de dados √© usada em todos os modelos. Ap√≥s separar os dados eu decidi fazer uma sobreamostragem (<em>oversampling</em>) dos dados de <strong>teste</strong> usando SMOTE<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, pois os dados s√£o muito desbalanceados. O motivo de eu usar essa t√©cnica apenas nos dados de teste √© que eu n√£o quero ter um resultado viesado, se eu sobreamostrar todo o banco de dados isso quer dizer que eu vou testar meu modelo no mesmo dado que eu o treinei, e este n√£o √© meu objetivo.</p><h3 id=avalia√ß√£o-dos-modelos>Avalia√ß√£o dos Modelos<a hidden class=anchor aria-hidden=true href=#avalia√ß√£o-dos-modelos>#</a></h3><p>Eu vou utilizar um classificador <em>dummy</em> para ter uma base para a medida de acur√°cia, e eu tamb√©m vou utilizar as m√©tricas: <code>precision</code> (precis√£o), <code>recall</code> (recorda√ß√£o) and <code>f1 score</code> (medida f1)<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Apesar de que o modelo <em>dummy</em> n√£o ter valor para essas m√©tricas eu vou manter ele para comparar a melhora dos modelos.</p><h3 id=modelo-base>Modelo Base<a hidden class=anchor aria-hidden=true href=#modelo-base>#</a></h3><p>O modelo base foi feito atrav√©s de um classificador <em>dummy</em>, basicamente ele diz que todos os clientes se comportam da mesma forma. Neste caso o modelo chutou que nenhum cliente iria deixar a empresa. Usando essa abordagem o modelo base obteve uma acur√°cia de <code>0,73456</code>.</p><p>A seguir todos os modelos ter√£o a mesma semente aleat√≥ria (<em>random state</em>).</p><h3 id=modelo-1---florestas-aleat√≥rias>Modelo 1 - Florestas Aleat√≥rias<a hidden class=anchor aria-hidden=true href=#modelo-1---florestas-aleat√≥rias>#</a></h3><p>Eu inicio usando uma busca no grid com valida√ß√£o cruzada (<em>grid search with cross-validation</em>) para encontrar os melhores par√¢metros dentro de uma sele√ß√£o de op√ß√µes utilizando o <code>recall</code> como estrat√©gia para avaliar a performance. O melhor modelo encontrado pela busca foi:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>RandomForestClassifier(criterion<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;entropy&#39;</span>, max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, max_leaf_nodes<span style=color:#f92672>=</span><span style=color:#ae81ff>70</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>22</span>)
</span></span></code></pre></div><p>Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:</p><ul><li>Medida Accuracy: 0,72534</li><li>Medida Precision: 0,48922</li><li>Medida Recall: 0,78877</li><li>Medida F1: 0,60389</li></ul><h3 id=modelo-2---classifica√ß√£o-de-vetores-de-suporte-linear>Modelo 2 - Classifica√ß√£o de Vetores de Suporte Linear<a hidden class=anchor aria-hidden=true href=#modelo-2---classifica√ß√£o-de-vetores-de-suporte-linear>#</a></h3><p>Neste modelo eu usei os par√¢metros padr√µes e aumentei o teto para o m√°ximo de itera√ß√µes para <code>900000</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>LinearSVC(max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>900000</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>22</span>)
</span></span></code></pre></div><p>Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:</p><ul><li>Medida Accuracy: 0,71966</li><li>Medida Precision: 0,48217</li><li>Medida Recall: 0,75936</li><li>Medida F1: 0,58982</li></ul><h3 id=modelo-3---rede-neural-multicamada-perceptron>Modelo 3 - Rede Neural Multicamada Perceptron<a hidden class=anchor aria-hidden=true href=#modelo-3---rede-neural-multicamada-perceptron>#</a></h3><p>Aqui eu fixei o solucionador LBFGS, pois de acordo com a documenta√ß√£o do <code>scikit-learn</code> ele tem uma performance melhor em banco de dados pequenos <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, e tamb√©m fiz uma busca no grid com valida√ß√£o cruzada para encontrar o melhor tamanho da camada oculta. O melhor modelo foi:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>MLPClassifier(hidden_layer_sizes<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>,), max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>9999</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>22</span>, solver<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;lbfgs&#39;</span>)
</span></span></code></pre></div><p>Ap√≥s ajustar o modelo, as medidas de avalia√ß√£o foram:</p><ul><li>Medida Accuracy: 0,72818</li><li>Medida Precision: 0,49133</li><li>Medida Recall: 0,68182</li><li>Medida F1: 0,57111</li></ul><h3 id=conclus√£o>Conclus√£o<a hidden class=anchor aria-hidden=true href=#conclus√£o>#</a></h3><p>Ap√≥s rodar os tr√™s modelos, todos usando o mesmo <code>random_state</code>. Eu encontrei as seguintes medidas de acur√°cia e melhorias no desempenho (comparado com o modelo base):</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/Challenge-Data-Science/main/3%20-%20Model%20Selection/results_table.png#center alt="results table"></p><p>No fim, a Floresta Aleat√≥ria teve as melhores m√©tricas. Este modelo consegue <em>recordar</em> uma grande parte dos clientes que evadem corretamente, ainda n√£o √© perfeito, mas j√° √© um ponto de partida. A medida de <em>acur√°cia</em> n√£o √© t√£o alta como eu gostaria, mas para este problema em particular o objetivo √© impedir os clientes de deixar a empresa e √© melhor utilizar recursos para manter um cliente que n√£o vai deixar a empresa do que n√£o fazer nada.</p><p>No fim, eu gostei desse desafio, pois √© raro eu praticar aprendizado de m√°quina, mas gra√ßas ao desafio eu tive a oportunidade de fazer um pequeno projeto nessa √°rea que √© t√£o importante e relevante. Essa foi a minha primeira vez trabalhando com redes neurais e ajuste de hiperpar√¢metros, e tenho certeza que na pr√≥xima vez terei resultados ainda melhores.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html>imbalanced-learn documentation</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9>Accuracy, Precision, Recall or F1? - Koo Ping Shung</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html>scikit-learn documentation</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://devmedeiros.com/pt/tags/storytelling/>storytelling</a></li><li><a href=https://devmedeiros.com/pt/tags/python/>python</a></li><li><a href=https://devmedeiros.com/pt/tags/an%C3%A1lise-de-dados/>an√°lise de dados</a></li><li><a href=https://devmedeiros.com/pt/tags/aprendizado-de-m%C3%A1quina/>aprendizado de m√°quina</a></li><li><a href=https://devmedeiros.com/pt/tags/rede-neural/>rede neural</a></li></ul><nav class=paginav><a class=prev href=https://devmedeiros.com/pt/post/alura-challenge-bi-2/><span class=title>¬´ P√°gina Anterior</span><br><span>Alura Challenge BI 2</span></a>
<a class=next href=https://devmedeiros.com/pt/post/2022-04-29-ux-power-bi-dashboards/><span class=title>Pr√≥xima P√°gina ¬ª</span><br><span>UX/UI em Dashboards de Business Intelligence</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Data Science Challenge - Churn Rate on twitter" href="https://twitter.com/intent/tweet/?text=Data%20Science%20Challenge%20-%20Churn%20Rate&amp;url=https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f&amp;hashtags=storytelling%2cpython%2can%c3%a1lisededados%2caprendizadodem%c3%a1quina%2credeneural"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Data Science Challenge - Churn Rate on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f&amp;title=Data%20Science%20Challenge%20-%20Churn%20Rate&amp;summary=Data%20Science%20Challenge%20-%20Churn%20Rate&amp;source=https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Data Science Challenge - Churn Rate on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Data Science Challenge - Churn Rate on whatsapp" href="https://api.whatsapp.com/send?text=Data%20Science%20Challenge%20-%20Churn%20Rate%20-%20https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Data Science Challenge - Churn Rate on telegram" href="https://telegram.me/share/url?text=Data%20Science%20Challenge%20-%20Churn%20Rate&amp;url=https%3a%2f%2fdevmedeiros.com%2fpt%2fpost%2f2022-05-30-churn-rate-challenge%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://giscus.app/client.js data-repo=devmedeiros/comments-devmedeiros data-repo-id=R_kgDOIcDZsA data-category=Announcements data-category-id=DIC_kwDOIcDZsM4CSkS1 data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the comments powered by giscus.</noscript></article></main><footer class=footer><span>&copy; 2021 - 2023 <a href=https://devmedeiros.com/terms/>Dev_Medeiros</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copiar";function s(){t.innerText="copiado!",setTimeout(()=>{t.innerText="copiar"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=https://devmedeiros.com/js/twemoji.min.js></script>
<script>twemoji.parse(document.body,{base:"https://devmedeiros.com/twemoji/",ext:".svg",folder:"svg"})</script></body></html>