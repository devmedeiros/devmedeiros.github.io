<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cleaning Credit Score Classification Dataset | Dev_Medeiros</title><meta name=keywords content="data cleaning,python,pandas,tutorial,kaggle,numpy,credit score,classification"><meta name=description content="How to come up with ways to clean a dataset using Python"><meta name=author content="Jaqueline Souza Medeiros"><link rel=canonical href=https://devmedeiros.com/post/data-cleaning-credit-score/><link crossorigin=anonymous href=/assets/css/stylesheet.481d2c214f23fd54f797bad0047ecdfe6eb5ae2f0f9da421b16ad57d95488cdd.css integrity="sha256-SB0sIU8j/VT3l7rQBH7N/m61ri8PnaQhsWrVfZVIjN0=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://devmedeiros.com/post/data-cleaning-credit-score/><link rel=alternate hreflang=pt href=https://devmedeiros.com/pt/post/data-cleaning-credit-score/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4W6Y2T4WX"></script>
<script>var dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D4W6Y2T4WX",{anonymize_ip:!0})}</script><meta property="og:title" content="Cleaning Credit Score Classification Dataset"><meta property="og:description" content="How to come up with ways to clean a dataset using Python"><meta property="og:type" content="article"><meta property="og:url" content="https://devmedeiros.com/post/data-cleaning-credit-score/"><meta property="og:image" content="https://i.imgur.com/RqLcJYv.jpg"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-07-24T13:06:00-03:00"><meta property="article:modified_time" content="2022-07-24T13:06:00-03:00"><meta property="og:site_name" content="Dev_Medeiros"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.imgur.com/RqLcJYv.jpg"><meta name=twitter:title content="Cleaning Credit Score Classification Dataset"><meta name=twitter:description content="How to come up with ways to clean a dataset using Python"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://devmedeiros.com/post/"},{"@type":"ListItem","position":2,"name":"Cleaning Credit Score Classification Dataset","item":"https://devmedeiros.com/post/data-cleaning-credit-score/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cleaning Credit Score Classification Dataset","name":"Cleaning Credit Score Classification Dataset","description":"How to come up with ways to clean a dataset using Python","keywords":["data cleaning","python","pandas","tutorial","kaggle","numpy","credit score","classification"],"articleBody":" Disclaimer: I’ll be talking about how to come up with the python code, if you want to read the actual code please go to this repo.\nMeet the Credit Score Classification Dataset The dataset that we’ll clean comes from kaggle, which is the train.csv dataset, but this could be used for the test.csv as well.\nThere are 28 columns and 100k rows in this dataset. I compiled a feature description table that you can see below.\nFeature Description ID Represents a unique identification of an entry Customer_ID Represents a unique identification of a person Month Represents the month of the year Name Represents the name of a person Age Represents the age of the person SSN Represents the social security number of a person Occupation Represents the occupation of the person Annual_Income Represents the annual income of the person Monthly_Inhand_Salary Represents the monthly base salary of a person Num_Bank_Accounts Represents the number of bank accounts a person holds Num_Credit_Card Represents the number of other credit cards held by a person Interest_Rate Represents the interest rate on a credit card Num_of_Loan Represents the number of loans taken from the bank Type_of_Loan Represents the types of loan taken by a person Delay_from_due_date Represents the average number of days delayed from the payment date Num_of_Delayed_Payment Represents the average number of payments delayed by a person Changed_Credit_Limit Represents the percentage change in credit card limit Num_Credit_Inquiries Represents the number of credit card inquiries Credit_Mix Represents the classification of the mix of credits Outstanding_Debt Represents the remaining debt to be paid (in USD) Credit_Utilization_Ratio Represents the utilization ratio of credit cards Credit_History_Age Represents the age of credit history of the person Payment_of_Min_Amount Represents whether only the minimum amount was paid by the person Total_EMI_per_month Represents the monthly EMI payments (in USD) Amount_invested_monthly Represents the monthly amount invested by the customer (in USD) Payment_Behaviour Represents the payment behavior of the customer (in USD) Monthly_Balance Represents the monthly balance amount of the customer (in USD) Credit_Score Represents the bracket of credit score (Poor, Standard, Good) Even though we have 100k rows, within these rows that are only 12,500 different customers, each customer appears 8 times (from January to August). So basically we can select a particular customer and look at their information and easily find incorrect data and be able to adjust it.\nCleaning Typos and Outliers In this dataset that is a lot of typos or just straight-up nonsense. You’ll find some values to be: _, !@9#%8, __10000__, NM or _______. I believe these typos are in the dataset to represent the improbability that you may find when dealing with real-world data and most of them mean that this is a null value.\nFor a moment I thought __10000__ would just be a typo, but there is no amount invested monthly that is over 200 dollars.\n__10000__ 4305 0.0 169 80.41529543900253 1 36.66235139442514 1 89.7384893604547 1 ... 36.541908593249026 1 93.45116318631192 1 140.80972223052834 1 38.73937670100975 1 167.1638651610451 1 Name: Amount_invested_monthly, Length: 91049, dtype: int64 Following this logic, I looked for nonsense in the data frame and I started to replace them with numpy nan’s. I also looked for outliers by looking at the distribution of values, if there was a value that only appeared once and was isolated I substitute it for a null value. I based this decision not only on this but also when I looked for customers that had this outlier and I observed all the data from this particular customer, I’d see weird things like:\nBy looking at this customer is clear that he didn’t make this much money annually only one month of the year.\nWhen you finish this search for typos and outliers don’t forget to assign the correct data type to your features. Some features like age started with string characters among the age values and because of this, it’s uploaded as an object instead of int or float.\nFilling Null Values After dealing with all the outliers and typos, we ended up with a lot of null values, as you can see:\ndf.isna().sum()[df.isna().sum() \u003e 0] Age 2776 Occupation 7062 Annual_Income 993 Monthly_Inhand_Salary 15002 Num_Credit_Card 2271 Interest_Rate 2034 Num_of_Loan 4348 Type_of_Loan 11408 Num_of_Delayed_Payment 7002 Changed_Credit_Limit 2091 Num_Credit_Inquiries 1965 Credit_Mix 20195 Credit_History_Age 9030 Payment_of_Min_Amount 12007 Amount_invested_monthly 8784 Payment_Behaviour 7600 Monthly_Balance 1200 dtype: int64 Instead of just dropping all these null values I first try to fill them using the information I already have. Remember that I said that a customer has historical data for 8 months? We can just use this historical data to fill the null values using an aggregation measurement of our choice filtering for the customer, this will be more accurate than just calculating the mean value of the database.\nI decided to use the average values for the following columns:\nmean_columns = [ 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Amount_invested_monthly', 'Monthly_Balance', 'Num_of_Loan', 'Num_Credit_Card', 'Interest_Rate', 'Annual_Income', 'Monthly_Inhand_Salary' ] And the last non-empty value for these:\nlast_columns = ['Age', 'Occupation', 'Type_of_Loan', 'Credit_Mix'] The reason for not using the mean for all my values is that I didn’t want to have someone be 20.5 years old and Occupation, Type_of_Loan, and Credit_Mix are discrete data.\nFeature Engineering With the clean data, we can proceed to feature engineering. In this case, we first want to change the Type_of_Loan, because that are some occurrences that it has all the loans in one value, as you can see:\nNot Specified, Mortgage Loan, Auto Loan, and Payday Loan 8 Payday Loan, Mortgage Loan, Debt Consolidation Loan, and Student Loan 8 Debt Consolidation Loan, Auto Loan, Personal Loan, Debt Consolidation Loan, Student Loan, and Credit-Builder Loan 8 Student Loan, Auto Loan, Student Loan, Credit-Builder Loan, Home Equity Loan, Debt Consolidation Loan, and Debt Consolidation Loan 8 Personal Loan, Auto Loan, Mortgage Loan, Student Loan, and Student Loan 8 Name: Type_of_Loan, Length: 5380, dtype: int64 So I’ll save all the different loan types in one vector, by splitting the loans every time there is a , or , and.\nloan_types = [] for index in df.index: temp = df.Type_of_Loan[index].replace('and ', '').split(', ') for i in temp: #loan in temp array if i not in loan_types: #if loan is not in loan_types loan_types.append(i) #add it Now we can create dummy variables of these loan_types, so a customer will receive the number 1 if they have this loan or a 0 if they don’t.\nfor loan in loan_types: df[loan] = 0 #create the loan column in the df with 0 for index in df.index: temp = df.Type_of_Loan[index].replace('and ', '').split(', ') if loan in temp: df.loc[index, loan] = 1 Now I want to keep working on this dataset to make it ready for training a machine learning model. For this reason, I need to transform my discrete data into numeric.\nThe feature Credit_History_Age has the values as strings “22 Years and 5 Months”, this pattern repeats itself, so we can take advantage of this and select the year multiplied by 12 and sum the month, resulting in a new feature with the credit history age in months. When we are done with this, there are still going to be null values, to fill them I choose to interpolate the values, this works great when the missing value is in February up until July because it interpolates with the customer’s credit history age, but it becomes a bad guessed when the missing value is in January or August.\nThe months’ names are going to be replaced by their number counterpart, so January is 1, February is 2, and so on. credit_mix and credit_score have 3 sequential categories, I choose to go with -1, 0, and 1, but you can use 1, 2, 3 and it’ll produce the same result.\nDon’t forget to check the GitHub Repository for the complete code mentioned here and the cleaned dataset.\n","wordCount":"1292","inLanguage":"en","image":"https://i.imgur.com/RqLcJYv.jpg","datePublished":"2022-07-24T13:06:00-03:00","dateModified":"2022-07-24T13:06:00-03:00","author":{"@type":"Person","name":"Jaqueline Souza Medeiros"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://devmedeiros.com/post/data-cleaning-credit-score/"},"publisher":{"@type":"Organization","name":"Dev_Medeiros","logo":{"@type":"ImageObject","url":"https://devmedeiros.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://devmedeiros.com/ accesskey=h title="Dev_Medeiros (Alt + H)">Dev_Medeiros</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://devmedeiros.com/pt/ title=Português aria-label=🇧🇷>🇧🇷</a></li></ul></div></div><ul id=menu><li><a href=https://devmedeiros.com/about/ title=about><span>about</span></a></li><li><a href=https://devmedeiros.com/post/ title=blog><span>blog</span></a></li><li><a href=https://devmedeiros.com/archives/ title=archives><span>archives</span></a></li><li><a href=https://devmedeiros.com/projects/ title=projects><span>projects</span></a></li><li><a href=https://devmedeiros.com/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><script src=https://code.jquery.com/jquery-3.4.1.slim.min.js integrity=sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js integrity=sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js integrity=sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6 crossorigin=anonymous></script><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://devmedeiros.com/>Home</a>&nbsp;»&nbsp;<a href=https://devmedeiros.com/post/>Posts</a></div><h1 class=post-title>Cleaning Credit Score Classification Dataset</h1><div class=post-meta><span title='2022-07-24 13:06:00 -0300 -0300'>July 24, 2022</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Jaqueline Souza Medeiros&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://devmedeiros.com/pt/post/data-cleaning-credit-score/>🇧🇷</a></li></ul></div></header><figure class=entry-cover><img loading=lazy src=https://i.imgur.com/RqLcJYv.jpg alt="a man wearing gloves cleaning a table with a cloth"><p>Profession photo created by freepik - freepik.com</p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#meet-the-credit-score-classification-dataset aria-label="Meet the Credit Score Classification Dataset">Meet the Credit Score Classification Dataset</a></li><li><a href=#cleaning-typos-and-outliers aria-label="Cleaning Typos and Outliers">Cleaning Typos and Outliers</a></li><li><a href=#filling-null-values aria-label="Filling Null Values">Filling Null Values</a></li><li><a href=#feature-engineering aria-label="Feature Engineering">Feature Engineering</a></li></ul></div></details></div><div class=post-content><blockquote><p><strong>Disclaimer:</strong> I&rsquo;ll be talking about how to come up with the python code, if you want to read the actual code please go to this <a href=https://github.com/devmedeiros/credit-score-classification-app/tree/main/notebooks>repo</a>.</p></blockquote><h2 id=meet-the-credit-score-classification-dataset>Meet the Credit Score Classification Dataset<a hidden class=anchor aria-hidden=true href=#meet-the-credit-score-classification-dataset>#</a></h2><p>The dataset that we&rsquo;ll clean comes from <a href="https://www.kaggle.com/datasets/parisrohan/credit-score-classification?select=train.csv">kaggle</a>, which is the <code>train.csv</code> dataset, but this could be used for the <code>test.csv</code> as well.</p><p>There are 28 columns and 100k rows in this dataset. I compiled a feature description table that you can see below.</p><table><thead><tr><th>Feature</th><th>Description</th></tr></thead><tbody><tr><td><code>ID</code></td><td>Represents a unique identification of an entry</td></tr><tr><td><code>Customer_ID</code></td><td>Represents a unique identification of a person</td></tr><tr><td><code>Month</code></td><td>Represents the month of the year</td></tr><tr><td><code>Name</code></td><td>Represents the name of a person</td></tr><tr><td><code>Age</code></td><td>Represents the age of the person</td></tr><tr><td><code>SSN</code></td><td>Represents the social security number of a person</td></tr><tr><td><code>Occupation</code></td><td>Represents the occupation of the person</td></tr><tr><td><code>Annual_Income</code></td><td>Represents the annual income of the person</td></tr><tr><td><code>Monthly_Inhand_Salary</code></td><td>Represents the monthly base salary of a person</td></tr><tr><td><code>Num_Bank_Accounts</code></td><td>Represents the number of bank accounts a person holds</td></tr><tr><td><code>Num_Credit_Card</code></td><td>Represents the number of other credit cards held by a person</td></tr><tr><td><code>Interest_Rate</code></td><td>Represents the interest rate on a credit card</td></tr><tr><td><code>Num_of_Loan</code></td><td>Represents the number of loans taken from the bank</td></tr><tr><td><code>Type_of_Loan</code></td><td>Represents the types of loan taken by a person</td></tr><tr><td><code>Delay_from_due_date</code></td><td>Represents the average number of days delayed from the payment date</td></tr><tr><td><code>Num_of_Delayed_Payment</code></td><td>Represents the average number of payments delayed by a person</td></tr><tr><td><code>Changed_Credit_Limit</code></td><td>Represents the percentage change in credit card limit</td></tr><tr><td><code>Num_Credit_Inquiries</code></td><td>Represents the number of credit card inquiries</td></tr><tr><td><code>Credit_Mix</code></td><td>Represents the classification of the mix of credits</td></tr><tr><td><code>Outstanding_Debt</code></td><td>Represents the remaining debt to be paid (in USD)</td></tr><tr><td><code>Credit_Utilization_Ratio</code></td><td>Represents the utilization ratio of credit cards</td></tr><tr><td><code>Credit_History_Age</code></td><td>Represents the age of credit history of the person</td></tr><tr><td><code>Payment_of_Min_Amount</code></td><td>Represents whether only the minimum amount was paid by the person</td></tr><tr><td><code>Total_EMI_per_month</code></td><td>Represents the monthly EMI payments (in USD)</td></tr><tr><td><code>Amount_invested_monthly</code></td><td>Represents the monthly amount invested by the customer (in USD)</td></tr><tr><td><code>Payment_Behaviour</code></td><td>Represents the payment behavior of the customer (in USD)</td></tr><tr><td><code>Monthly_Balance</code></td><td>Represents the monthly balance amount of the customer (in USD)</td></tr><tr><td><code>Credit_Score</code></td><td>Represents the bracket of credit score (Poor, Standard, Good)</td></tr></tbody></table><p>Even though we have 100k rows, within these rows that are only 12,500 different customers, each customer appears 8 times (from January to August). So basically we can select a particular customer and look at their information and easily find incorrect data and be able to adjust it.</p><h2 id=cleaning-typos-and-outliers>Cleaning Typos and Outliers<a hidden class=anchor aria-hidden=true href=#cleaning-typos-and-outliers>#</a></h2><p>In this dataset that is a lot of typos or just straight-up nonsense. You&rsquo;ll find some values to be: <code>_</code>, <code>!@9#%8</code>, <code>__10000__</code>, <code>NM</code> or <code>_______</code>. I believe these typos are in the dataset to represent the improbability that you may find when dealing with real-world data and most of them mean that this is a null value.</p><p>For a moment I thought <code>__10000__</code> would just be a typo, but there is no amount invested monthly that is over 200 dollars.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>__10000__             4305
</span></span><span style=display:flex><span>0.0                    169
</span></span><span style=display:flex><span>80.41529543900253        1
</span></span><span style=display:flex><span>36.66235139442514        1
</span></span><span style=display:flex><span>89.7384893604547         1
</span></span><span style=display:flex><span>                      ... 
</span></span><span style=display:flex><span>36.541908593249026       1
</span></span><span style=display:flex><span>93.45116318631192        1
</span></span><span style=display:flex><span>140.80972223052834       1
</span></span><span style=display:flex><span>38.73937670100975        1
</span></span><span style=display:flex><span>167.1638651610451        1
</span></span><span style=display:flex><span>Name: Amount_invested_monthly, Length: 91049, dtype: int64
</span></span></code></pre></div><p>Following this logic, I looked for nonsense in the data frame and I started to replace them with numpy <code>nan</code>&rsquo;s. I also looked for outliers by looking at the distribution of values, if there was a value that only appeared once and was isolated I substitute it for a null value. I based this decision not only on this but also when I looked for customers that had this outlier and I observed all the data from this particular customer, I&rsquo;d see weird things like:</p><p><img loading=lazy src=https://raw.githubusercontent.com/devmedeiros/credit-score-classification-app/main/reports/figures/annual_income.png#center alt="a table displaying information on a given customer and showing an outlier on its annual income"></p><p>By looking at this customer is clear that he didn&rsquo;t make this much money annually only one month of the year.</p><p>When you finish this search for typos and outliers don&rsquo;t forget to assign the correct data type to your features. Some features like <code>age</code> started with string characters among the age values and because of this, it&rsquo;s uploaded as an object instead of int or float.</p><h2 id=filling-null-values>Filling Null Values<a hidden class=anchor aria-hidden=true href=#filling-null-values>#</a></h2><p>After dealing with all the outliers and typos, we ended up with a lot of null values, as you can see:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=color:#f92672>.</span>isna()<span style=color:#f92672>.</span>sum()[df<span style=color:#f92672>.</span>isna()<span style=color:#f92672>.</span>sum() <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Age                         2776
</span></span><span style=display:flex><span>Occupation                  7062
</span></span><span style=display:flex><span>Annual_Income                993
</span></span><span style=display:flex><span>Monthly_Inhand_Salary      15002
</span></span><span style=display:flex><span>Num_Credit_Card             2271
</span></span><span style=display:flex><span>Interest_Rate               2034
</span></span><span style=display:flex><span>Num_of_Loan                 4348
</span></span><span style=display:flex><span>Type_of_Loan               11408
</span></span><span style=display:flex><span>Num_of_Delayed_Payment      7002
</span></span><span style=display:flex><span>Changed_Credit_Limit        2091
</span></span><span style=display:flex><span>Num_Credit_Inquiries        1965
</span></span><span style=display:flex><span>Credit_Mix                 20195
</span></span><span style=display:flex><span>Credit_History_Age          9030
</span></span><span style=display:flex><span>Payment_of_Min_Amount      12007
</span></span><span style=display:flex><span>Amount_invested_monthly     8784
</span></span><span style=display:flex><span>Payment_Behaviour           7600
</span></span><span style=display:flex><span>Monthly_Balance             1200
</span></span><span style=display:flex><span>dtype: int64
</span></span></code></pre></div><p>Instead of just dropping all these null values I first try to fill them using the information I already have. Remember that I said that a customer has historical data for 8 months? We can just use this historical data to fill the null values using an aggregation measurement of our choice filtering for the customer, this will be more accurate than just calculating the mean value of the database.</p><p>I decided to use the average values for the following columns:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>mean_columns <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Num_of_Delayed_Payment&#39;</span>, <span style=color:#e6db74>&#39;Changed_Credit_Limit&#39;</span>, <span style=color:#e6db74>&#39;Num_Credit_Inquiries&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Amount_invested_monthly&#39;</span>, <span style=color:#e6db74>&#39;Monthly_Balance&#39;</span>, <span style=color:#e6db74>&#39;Num_of_Loan&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Num_Credit_Card&#39;</span>, <span style=color:#e6db74>&#39;Interest_Rate&#39;</span>, <span style=color:#e6db74>&#39;Annual_Income&#39;</span>, <span style=color:#e6db74>&#39;Monthly_Inhand_Salary&#39;</span>
</span></span><span style=display:flex><span>    ]
</span></span></code></pre></div><p>And the last non-empty value for these:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>last_columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Age&#39;</span>, <span style=color:#e6db74>&#39;Occupation&#39;</span>, <span style=color:#e6db74>&#39;Type_of_Loan&#39;</span>, <span style=color:#e6db74>&#39;Credit_Mix&#39;</span>]
</span></span></code></pre></div><p>The reason for not using the mean for all my values is that I didn&rsquo;t want to have someone be 20.5 years old and <code>Occupation</code>, <code>Type_of_Loan</code>, and <code>Credit_Mix</code> are discrete data.</p><h2 id=feature-engineering>Feature Engineering<a hidden class=anchor aria-hidden=true href=#feature-engineering>#</a></h2><p>With the clean data, we can proceed to feature engineering. In this case, we first want to change the <code>Type_of_Loan</code>, because that are some occurrences that it has all the loans in one value, as you can see:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Not Specified, Mortgage Loan, Auto Loan, and Payday Loan                                                                                         8
</span></span><span style=display:flex><span>Payday Loan, Mortgage Loan, Debt Consolidation Loan, and Student Loan                                                                            8
</span></span><span style=display:flex><span>Debt Consolidation Loan, Auto Loan, Personal Loan, Debt Consolidation Loan, Student Loan, and Credit-Builder Loan                                8
</span></span><span style=display:flex><span>Student Loan, Auto Loan, Student Loan, Credit-Builder Loan, Home Equity Loan, Debt Consolidation Loan, and Debt Consolidation Loan               8
</span></span><span style=display:flex><span>Personal Loan, Auto Loan, Mortgage Loan, Student Loan, and Student Loan                                                                          8
</span></span><span style=display:flex><span>Name: Type_of_Loan, Length: 5380, dtype: int64
</span></span></code></pre></div><p>So I&rsquo;ll save all the different loan types in one vector, by splitting the loans every time there is a <code>,</code> or <code>, and</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>loan_types <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>index:
</span></span><span style=display:flex><span>    temp <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>Type_of_Loan[index]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;and &#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;, &#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> temp: <span style=color:#75715e>#loan in temp array</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> i <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> loan_types: <span style=color:#75715e>#if loan is not in loan_types</span>
</span></span><span style=display:flex><span>            loan_types<span style=color:#f92672>.</span>append(i) <span style=color:#75715e>#add it</span>
</span></span></code></pre></div><p>Now we can create dummy variables of these <code>loan_types</code>, so a customer will receive the number 1 if they have this loan or a 0 if they don&rsquo;t.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span> loan <span style=color:#f92672>in</span> loan_types:
</span></span><span style=display:flex><span>    df[loan] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span> <span style=color:#75715e>#create the loan column in the df with 0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>index:
</span></span><span style=display:flex><span>        temp <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>Type_of_Loan[index]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;and &#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;, &#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> loan <span style=color:#f92672>in</span> temp:
</span></span><span style=display:flex><span>            df<span style=color:#f92672>.</span>loc[index, loan] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><p>Now I want to keep working on this dataset to make it ready for training a machine learning model. For this reason, I need to transform my discrete data into numeric.</p><p>The feature <code>Credit_History_Age</code> has the values as strings &ldquo;22 Years and 5 Months&rdquo;, this pattern repeats itself, so we can take advantage of this and select the year multiplied by 12 and sum the month, resulting in a new feature with the credit history age in months. When we are done with this, there are still going to be null values, to fill them I choose to interpolate the values, this works great when the missing value is in February up until July because it interpolates with the customer&rsquo;s credit history age, but it becomes a bad guessed when the missing value is in January or August.</p><p>The months&rsquo; names are going to be replaced by their number counterpart, so January is 1, February is 2, and so on. <code>credit_mix</code> and <code>credit_score</code> have 3 sequential categories, I choose to go with -1, 0, and 1, but you can use 1, 2, 3 and it&rsquo;ll produce the same result.</p><p>Don&rsquo;t forget to check the GitHub <a href=https://github.com/devmedeiros/credit-score-classification-app/tree/main/>Repository</a> for the complete code mentioned here and the cleaned dataset.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://devmedeiros.com/tags/data-cleaning/>data cleaning</a></li><li><a href=https://devmedeiros.com/tags/python/>python</a></li><li><a href=https://devmedeiros.com/tags/pandas/>pandas</a></li><li><a href=https://devmedeiros.com/tags/tutorial/>tutorial</a></li><li><a href=https://devmedeiros.com/tags/kaggle/>kaggle</a></li><li><a href=https://devmedeiros.com/tags/numpy/>numpy</a></li><li><a href=https://devmedeiros.com/tags/credit-score/>credit score</a></li><li><a href=https://devmedeiros.com/tags/classification/>classification</a></li></ul><nav class=paginav><a class=prev href=https://devmedeiros.com/post/credit-score-classification-app/><span class=title>« Prev</span><br><span>Credit Score Classification App</span></a>
<a class=next href=https://devmedeiros.com/post/alura-challenge-bi-2/><span class=title>Next »</span><br><span>Alura Challenge BI 2</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Cleaning Credit Score Classification Dataset on twitter" href="https://twitter.com/intent/tweet/?text=Cleaning%20Credit%20Score%20Classification%20Dataset&amp;url=https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f&amp;hashtags=datacleaning%2cpython%2cpandas%2ctutorial%2ckaggle%2cnumpy%2ccreditscore%2cclassification"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Cleaning Credit Score Classification Dataset on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f&amp;title=Cleaning%20Credit%20Score%20Classification%20Dataset&amp;summary=Cleaning%20Credit%20Score%20Classification%20Dataset&amp;source=https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Cleaning Credit Score Classification Dataset on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Cleaning Credit Score Classification Dataset on whatsapp" href="https://api.whatsapp.com/send?text=Cleaning%20Credit%20Score%20Classification%20Dataset%20-%20https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Cleaning Credit Score Classification Dataset on telegram" href="https://telegram.me/share/url?text=Cleaning%20Credit%20Score%20Classification%20Dataset&amp;url=https%3a%2f%2fdevmedeiros.com%2fpost%2fdata-cleaning-credit-score%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://giscus.app/client.js data-repo=devmedeiros/comments-devmedeiros data-repo-id=R_kgDOIcDZsA data-category=Announcements data-category-id=DIC_kwDOIcDZsM4CSkS1 data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the comments powered by giscus.</noscript></article></main><footer class=footer><span>&copy; 2021 - 2023 <a href=https://devmedeiros.com/terms/>Dev_Medeiros</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=https://devmedeiros.com/js/twemoji.min.js></script>
<script>twemoji.parse(document.body,{base:"https://devmedeiros.com/twemoji/",ext:".svg",folder:"svg"})</script></body></html>