<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Feature Selection | Dev_Medeiros</title><meta name=keywords content="feature selection,scikit-learn"><meta name=description content="Defining feature selection and showing how you can select features in Machine Learning"><meta name=author content="Jaqueline Souza Medeiros"><link rel=canonical href=https://devmedeiros.com/post/2022-06-14-feature-selection/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://devmedeiros.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://devmedeiros.com/post/2022-06-14-feature-selection/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4W6Y2T4WX"></script>
<script>var dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D4W6Y2T4WX",{anonymize_ip:!0})}</script><meta property="og:title" content="Feature Selection"><meta property="og:description" content="Defining feature selection and showing how you can select features in Machine Learning"><meta property="og:type" content="article"><meta property="og:url" content="https://devmedeiros.com/post/2022-06-14-feature-selection/"><meta property="og:image" content="https://devmedeiros.com/cover.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-06-14T19:23:00-03:00"><meta property="article:modified_time" content="2022-06-14T19:23:00-03:00"><meta property="og:site_name" content="Dev_Medeiros"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://devmedeiros.com/cover.png"><meta name=twitter:title content="Feature Selection"><meta name=twitter:description content="Defining feature selection and showing how you can select features in Machine Learning"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://devmedeiros.com/post/"},{"@type":"ListItem","position":2,"name":"Feature Selection","item":"https://devmedeiros.com/post/2022-06-14-feature-selection/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Feature Selection","name":"Feature Selection","description":"Defining feature selection and showing how you can select features in Machine Learning","keywords":["feature selection","scikit-learn"],"articleBody":"What is feature selection? Feature selection is the process of finding pertinent features and eliminating unnecessary, redundant, or noisy data. It can be useful to help the training process be faster and it can also avoid overfitting. According to Munson and Caruana, the goal of feature selection is to identify the feature set that best balances the risks of having too few features with the risks of having too many features. It can also help improve the prediction accuracy and the interpretation of models.1 2\nI chose three methods for feature selection to show, but these are not all available methods, in the scikit-learn package that are 17 algorithms implemented at the time of writing. 3\nCorrelation among features Correlation among features can bring unnecessary noise to your model. Because a high correlation means that when one feature increases the other increases as well (or decreases if is negative). So if two features have a high correlation they aren‚Äôt bringing any new information to our model, in this case, is best to choose one of them to keep and drop the other.\nLook at the following correlation matrix, for example:\nWe can see that height and weight are heavily correlated with BMI, we don‚Äôt need to keep these three features, we can drop height and weight and keep just the BMI, or depending on what you want with the model you just drop the BMI.\nLow Variance Removing features with low variance is a simple method of feature selection. You can set a minimal variance a feature needs to determine if it continues in the model or not. The reasoning behind this is that a low variance means it has a small effect on the final model.\nAlthough there isn‚Äôt concrete information on what is a ‚Äúlow variance‚Äù, the scikit-learn default option for this method is 0, but you can test other values for your dataset and see what works best for you.\nRecursive feature elimination The purpose of recursive feature elimination (RFE) is to pick features by iteratively considering smaller and smaller sets of features given an external estimator that assigns weights to features. The importance of each feature is first determined through any particular attribute, and the estimator is then trained on the initial set of features. The least crucial features are then removed from the present list of features. On the pruned set, that process is continued recursively until the target number of features to select is eventually attained. 4\nMUNSON, M. Arthur; CARUANA, Rich. On feature selection, bias-variance, and bagging. In:¬†Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Berlin, Heidelberg, 2009. p. 144-159.¬†‚Ü©Ô∏é\nKUMAR, Vipin; MINZ, Sonajharia. Feature selection: a literature review.¬†SmartCR, v. 4, n. 3, p. 211-229, 2014.¬†‚Ü©Ô∏é\nAPI Reference ‚Äî scikit-learn 1.1.1 documentation¬†‚Ü©Ô∏é\n1.13. Feature selection ‚Äî scikit-learn 1.1.1 documentation¬†‚Ü©Ô∏é\n","wordCount":"472","inLanguage":"en","datePublished":"2022-06-14T19:23:00-03:00","dateModified":"2022-06-14T19:23:00-03:00","author":{"@type":"Person","name":"Jaqueline Souza Medeiros"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://devmedeiros.com/post/2022-06-14-feature-selection/"},"publisher":{"@type":"Organization","name":"Dev_Medeiros","logo":{"@type":"ImageObject","url":"https://devmedeiros.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://devmedeiros.com/ accesskey=h title="Dev_Medeiros (Alt + H)">Dev_Medeiros</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://devmedeiros.com/pt/ title=Portugu√™s aria-label=üáßüá∑>Pt</a></li></ul></div></div><ul id=menu><li><a href=https://devmedeiros.com/about/ title=about><span>about</span></a></li><li><a href=https://devmedeiros.com/post/ title=blog><span>blog</span></a></li><li><a href=https://devmedeiros.com/archives/ title=archives><span>archives</span></a></li><li><a href=https://devmedeiros.com/projects/ title=projects><span>projects</span></a></li><li><a href=https://devmedeiros.com/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><script src=https://code.jquery.com/jquery-3.4.1.slim.min.js integrity=sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js integrity=sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js integrity=sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6 crossorigin=anonymous></script><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://devmedeiros.com/>Home</a>&nbsp;¬ª&nbsp;<a href=https://devmedeiros.com/post/>Posts</a></div><h1 class=post-title>Feature Selection</h1><div class=post-meta><span title='2022-06-14 19:23:00 -0300 -0300'>June 14, 2022</span>&nbsp;¬∑&nbsp;3 min&nbsp;¬∑&nbsp;Jaqueline Souza Medeiros</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#what-is-feature-selection aria-label="What is feature selection?">What is feature selection?</a></li><li><a href=#correlation-among-features aria-label="Correlation among features">Correlation among features</a></li><li><a href=#low-variance aria-label="Low Variance">Low Variance</a></li><li><a href=#recursive-feature-elimination aria-label="Recursive feature elimination">Recursive feature elimination</a></li></ul></div></details></div><div class=post-content><h1 id=what-is-feature-selection>What is feature selection?<a hidden class=anchor aria-hidden=true href=#what-is-feature-selection>#</a></h1><p>Feature selection is the process of finding pertinent features and eliminating unnecessary, redundant, or noisy data. It can be useful to help the training process be faster and it can also avoid overfitting. According to Munson and Caruana, the goal of feature selection is to identify the feature set that best balances the risks of having too few features with the risks of having too many features. It can also help improve the prediction accuracy and the interpretation of models.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>I chose three methods for feature selection to show, but these are not all available methods, in the <code>scikit-learn</code> package that are 17 algorithms implemented at the time of writing. <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><h1 id=correlation-among-features>Correlation among features<a hidden class=anchor aria-hidden=true href=#correlation-among-features>#</a></h1><p>Correlation among features can bring unnecessary noise to your model. Because a high correlation means that when one feature increases the other increases as well (or decreases if is negative). So if two features have a high correlation they aren‚Äôt bringing any new information to our model, in this case, is best to choose one of them to keep and drop the other.</p><p>Look at the following correlation matrix, for example:</p><p><img loading=lazy src="https://ik.imagekit.io/devmedeiros/out_w4T4rFn5h.png?ik-sdk-version=javascript-1.4.3&updatedAt=1655244061311#center" alt="small correlation plot with weight, height and BMI"></p><p>We can see that height and weight are heavily correlated with BMI, we don‚Äôt need to keep these three features, we can drop height and weight and keep just the BMI, or depending on what you want with the model you just drop the BMI.</p><h1 id=low-variance>Low Variance<a hidden class=anchor aria-hidden=true href=#low-variance>#</a></h1><p>Removing features with low variance is a simple method of feature selection. You can set a minimal variance a feature needs to determine if it continues in the model or not. The reasoning behind this is that a low variance means it has a small effect on the final model.</p><p>Although there isn&rsquo;t concrete information on what is a &ldquo;low variance&rdquo;, the <code>scikit-learn</code> default option for this method is 0, but you can test other values for your dataset and see what works best for you.</p><h1 id=recursive-feature-elimination>Recursive feature elimination<a hidden class=anchor aria-hidden=true href=#recursive-feature-elimination>#</a></h1><p>The purpose of recursive feature elimination (RFE) is to pick features by iteratively considering smaller and smaller sets of features given an external estimator that assigns weights to features. The importance of each feature is first determined through any particular attribute, and the estimator is then trained on the initial set of features. The least crucial features are then removed from the present list of features. On the pruned set, that process is continued recursively until the target number of features to select is eventually attained. <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://link.springer.com/chapter/10.1007/978-3-642-04174-7_10>MUNSON, M. Arthur; CARUANA, Rich. On feature selection, bias-variance, and bagging. In:¬†<strong>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</strong>. Springer, Berlin, Heidelberg, 2009. p. 144-159.</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://faculty.cc.gatech.edu/~hic/CS7616/Papers/Kumar-Minz-2014.pdf>KUMAR, Vipin; MINZ, Sonajharia. Feature selection: a literature review.¬†<strong>SmartCR</strong>, v. 4, n. 3, p. 211-229, 2014.</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection>API Reference ‚Äî scikit-learn 1.1.1 documentation</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://scikit-learn.org/stable/modules/feature_selection.html>1.13. Feature selection ‚Äî scikit-learn 1.1.1 documentation</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://devmedeiros.com/tags/feature-selection/>feature selection</a></li><li><a href=https://devmedeiros.com/tags/scikit-learn/>scikit-learn</a></li></ul><nav class=paginav><a class=prev href=https://devmedeiros.com/post/alura-challenge-bi-2/><span class=title>¬´ Prev</span><br><span>Alura Challenge BI 2</span></a>
<a class=next href=https://devmedeiros.com/post/2022-05-30-churn-rate-challenge/><span class=title>Next ¬ª</span><br><span>Data Science Challenge - Churn Rate</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Feature Selection on twitter" href="https://twitter.com/intent/tweet/?text=Feature%20Selection&url=https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f&hashtags=featureselection%2cscikit-learn"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Feature Selection on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f&title=Feature%20Selection&summary=Feature%20Selection&source=https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Feature Selection on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Feature Selection on whatsapp" href="https://api.whatsapp.com/send?text=Feature%20Selection%20-%20https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Feature Selection on telegram" href="https://telegram.me/share/url?text=Feature%20Selection&url=https%3a%2f%2fdevmedeiros.com%2fpost%2f2022-06-14-feature-selection%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2021 - 2022 <a href=https://devmedeiros.com/terms/>Dev_Medeiros</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>